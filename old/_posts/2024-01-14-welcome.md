# Data base notes

#### Data base

defninition : set of named relations 我们把它画成can(罐头）的形状
Relation(Table):
- Schema:description (“metadata”)
- Instance:set of data satisfying the schema
#### Attribute （属性）
Column ,fileld
#### DDL - Data Definition Language
DDL 用于修改和定义数据库的模式结构，通过ddl你可以创建/修改删除数据库表格和其他对象，比如 使用’CREAETE TABLE’,’ALTER TABLE’,’DROP TABLE’等命令来创建，修改或者删除表
#### DML - Data Manipulation Language
DML用于数据库中的数据进行操作，包括插入，查询和更新数据。它允许用户便携查询来检索数据(使用’SELECT’）和更新数据(使用’UPDATE’)、插入新数据’INSERT’和删除数据，使用’DELETE’

#### RDBMS(关系型数据库）
关系表
–unique attribute names, atomic types
#### MySQL与NoSQL的区别
MySQL是一种关系数据库管理系统（RDBMS），它使用结构化查询语言（SQL）来管理存储在表中的数据。MySQL中的数据是以行和列的形式存储的，非常适合处理结构化数据。关系数据库非常擅长处理复杂的查询，因为它们可以非常高效地在多个表之间建立关系。

NoSQL是指非关系型数据库，这是一个总称，包括了多种不同类型的数据库，比如文档数据库（如MongoDB）、键值存储（如Redis）、宽列存储（如Cassandra）和图形数据库（如Neo4j）。NoSQL数据库不使用传统的表格结构来存储数据，因此它们可以非常灵活地处理不规则或半结构化的数据。NoSQL数据库通常在处理大量数据和高并发请求时表现更好，因为它们的设计更注重性能、可扩展性和灵活性。

SQL查询分为以下几个阶段:
Parsing：将SQL语句分解成可理解的片段。
check: 检查语法是否正确。
veirify:验证所引用的表格和列是否存在。
语义检查：
确认查询中的字段、条件和函数是否有意义和相关。
查询优化：
确定执行查询的最有效率的方法。
可能包括选择使用哪个索引、如何连接表以及在什么顺序上执行操作。
查询解析：DBMS的查询解析器将SQL查询转换为一种内部格式，以便进一步处理。
查询优化：优化器将解析好的查询进行分析，并尝试找到执行查询的最有效路径。
查询执行：执行器按照优化器确定的路径执行查询，访问数据库中的数据，并进行必要的操作（如选择、连接、排序等）。
结果返回：执行完毕后，DBMS将结果集返回给SQL客户端，供用户查看。

The SQL DDL: The sailors

```mysql

CREATE TABLE SAILORS(sid INTEGER,
sname CHAR(20),
rating INTEGER,
age FLOAT,
PRIMARY KEY (sid));
```
- **CREATE TABLE Sailors**: 这表示要创建一个新的表格，表格的名字是 **Sailors**。
- **sid INTEGER**: 这定义了表中的一个列（字段），名为 **sid**，数据类型为 **INTEGER**。这意味着在这个列中可以存储整数值。
- **sname CHAR(20)**: 这定义了另一个列，名为 **sname**，数据类型为 **CHAR(20)**。**CHAR** 是字符数据类型，括号内的数字表示字符的最大长度，这里是20个字符。所以 **sname** 可以存储最多20个字符的字符串。
- **rating INTEGER**: 这又定义了一个列，名为 **rating**，数据类型为 **INTEGER**，与 **sid** 类似，可以存储整数值。
- **age FLOAT**: 最后定义了一个名为 **age** 的列，其数据类型为 **FLOAT**。**FLOAT** 数据类型用于存储带有小数点的数值，即浮点数

#### Primary Key columns
Provides a unique “lookup key” for the relation (在表中是唯一的）
Cannot have any duplicate values
Can be made up of \>1 columns

#### Foreign Key
在关系型数据库中，外键(FOREIGN KEY)是用来创建两个表之间联系的一种数据库的约束。外键指向的是另一个表的主键，这样可以维护跨表的数据的完整性和关系

#### Basic Single Table Quries
```mysql
SELECT [DISTINCT] <column expression list>
FROM <single table>
[WHERE <predicate>]
Simplest version is straight forward 
```



- produce all tuples in the table that satisfy the predicate 
- output the expression in the SELECT list 
- Expression can be a column reference or an arithmetic expression over column refs
#### HAVING

```mysql
SELECT [DISTINCT] AVG(S.gpa), S.dept
FROM Students S
GROUP BY S.dept
HAVING COUNT(*) > 2
```




#### LIMIT语句
LIMIT子句只用于产生指定数量的结果航，这里是三行，LIMIT 语句通常要和’ORDER BY’一起使用 ，因为如果没有ORDER BY 结果的顺序是不确定的，返回哪三行也成为不确定的 没有ORDER BY的LIMIT使用不是"纯粹的"声明性构造，因为没有排序，所返回的记录取决于查询处理的算法。
总结起来就是

```mysql
SELECT [DISTINCT] <column expression list>
FROM <single table>
[WHERE <predicate> ]
[GROUP BY <column list>
[HAVING <predicate> ] ]
[ORDER BY <column list> ]
[LIMIT <integer>];
```





###### Column Names and Table Aliases

```mysql
SELECT Sailors.sid,sname,bid
FROM Sailors,Reseerves
WHERE Sailors.sid = Reserves.sid

SELECT S.sid,sname,bid
FROM Sailors AS S,Reserves AS R
WHERE S.sid = R.sid
```





#### 集合Set Sematics
UNION 并
INTERSECT 交 
EXCEPT 
#### SQL嵌套查询
核心是IN/NOT IN/EXISTS关键字
或者 op ANY/ALL
SELECT S.sname
FROM Sailors S
WHERE S.sid IN (SELECT R.sid
```
            FROM Reserves R
            WHERE R.bid=102)
```

子查询：(SELECT R.sid FROM Reserves R WHERE R.bid=102) 这部分查询从"Reserves"表中找出所有预订了编号为102的船只的水手的ID（sid）。
主查询：SELECT S.sname FROM Sailors S WHERE S.sid IN ... 这部分查询从"Sailors"表中选择那些其ID（sid）出现在子查询结果中的水手的名字（sname）
#### EXIST 操作符

```mysql
SELECT S.sname
FROM Sailors S
WHERE EXISTS
  (SELECT R.sid
   FROM Reserves R
   WHERE R.bid=103)
```




这个查询检查是否存在至少一个在Reserves表中为船只编号103做出预约的水手，如果存在，那么外层查询就会返回所有水手的名字。注意，虽然这个查询语法上是合法的，但由于外层查询没有引用内层查询的任何结果，所以实际上它会返回Sailors表中所有水手的名字，只要Reserves表中存在至少一条bid为103的记录。这意味着，无论Reserves表中哪个水手预约了编号为103的船，结果都将是Sailors表中所有水手的名单。这可能不是查询最初的意图，因为通常我们期望的是只返回那些确实预约了船只的水手的名字。

###### 关系除法(relational division)

关系除法用来找出一组满足条件的所有记录，在这个例子中是“找出预定了所有船只的水手”
SELECT S.sname
FROM Sailors S
WHERE NOT EXISTS

```mysql
  (SELECT B.bid
   FROM Boats B
   WHERE NOT EXISTS
         (SELECT R.bid
          FROM Reserves R
          WHERE R.bid = B.bid AND R.sid = S.sid))
```

**最内层的NOT EXIST 查询** :对于每一艘船只 b.bid 它检查是否有像对应的预定记录在Reserve 表中 
#### WHERE NOT EXISTS
其中 WHERE NOT EXIST 子句用来测试是否不返回任何结果。如果子查询没有返回任何行，整个WHERE NOT EXISTS 表大致为真 否则为假
#### BOOLEAN布尔值
SELECT R.sid
FROM Boats B,Reserves R
WHERE R.bid = B.bid AND 
```
(B.color = 'red' OR B.color = 'green')
```
#### 算数运算符(Arithmetic Expressions)
SELECT S.age,S.age-5 AS age1,2\*S.age AS age2
FROM Sailors AS S
WHERE S.name = 'Popeye'

SELECT S1.name AS name1,S2.name AS name2
FROM Sailors AS S1,Sailors AS S2
WHERE 2\*S1.rating = S2.rating -1
#### 比较操作符
ANY 如果比较符为真，与子查询返回的任意一个值相比
ALL 只有当操作弗比较对所有子查询都是真，才返回真
SELECT \*
FROM Sailors S
WHERE S.rating \> ANY

```mysql
  (SELECT S2.rating
   FROM Sailors S2
   WHERE S2.sname='Popeye')
```
#### 最大值参数

```mysql 
SELECT *
FROM Sailors S
WHERE S.rating = (SELECT MAX(S2.rating) FROM Sailors S2)

SELECT *
FROM Sailors S
WHERE S.rating >= ALL (SELECT S2.rating FROM Sailors S2)
选择了sailor 中的所有列，条件是水手的评分要大于或等于表中其他水手的评分。
SELECT *
FROM Sailors S
ORDER BY rating DESC
LIMIT 1;
```



典型错误的写法:

```mysql
SELECT MAX(S.rating) FROM Sailors S;
```

这个查询返回Sailors表中最高的评级值，但它不返回具有该评级的水手的任何其他信息。
SELECT S.\*, MAX(S.rating) FROM Sailors S;
这个查询试图返回所有的列（S.）以及最高的评级值。但这种写法是错误的，因为它没有正确地使用聚合函数MAX。在没有GROUP BY子句的情况下，你不能同时选择所有列（S.）和一个聚合列（MAX(S.rating)），除非聚合列是在子查询中使用。

#### UNION ALL,INTERSECT ALL
UNION ALL : sum of cardinalities
{A(4+2),B(2+3),C(1+1),D(1+0),E(0+1)}
INTERSECT ALL
{A(min(4,2)),B(min(2,3)),C(min(1,1)),D(min(1,0)),E(min(0,1))}
EXCEPT ALL:difference of cardinalities
{A(4-2},B(2-3),C(1-1),D(1-0),E(0-1)} = {A,A,D}
#### Inner join

```mysql
SELECT s.\*,r.bid
FROM Sailors s, Reserves r
WHERE s.sid = r.sid
AND ...
SELECT s.\*, r.bid
FROM Sailors s INNER JOIN Reserves r
ON s.sid = r.sid
WHERE ...
```



#### SQL join 模板

```mysql
SELECT <column expression list>
FROM table_name
[INNER | NATURAL | {LEFT | RIGHT | FULL } {OUTER}] JOIN table_name
ON <qualification list>
WHERE ...
<column expression list>: 这是你想要从连接的结果集中选择的列或表达式的列表。
<qualification list>: 这是ON子句中指定的条件，它确定如何连接两个表。对于NATURAL JOIN，不需要这个。
WHERE ...: 这是一个过滤器，用于返回连接操作后满足特定条件的行
```

INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录。 LEFT JOIN（左连接）：获取左表所有记录，即使右表没有对应匹配的记录。 RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。

这里是 COUNT(\*) 的一些关键点：

```
•	COUNT(*) 计算的是所有行的数量，包括那些包含 NULL 值的行。
•	与 COUNT(*) 相比，COUNT(column_name) 仅计算指定列中非 NULL 值的数量。如果指定的列中含有 NULL 值，则这些行不会被包含在计数中。
•	COUNT(1) 与 COUNT(*) 功能相同，都是用来计数行数，但 COUNT(*) 在多数数据库系统中更为常用和标准。
```

在使用聚合函数如 COUNT(\*) 时，通常会与 GROUP BY 子句结合使用，来计算分组后每组的行数。例如，如果你想知道每个客户有多少条订单记录，你可以编写类似下面的 SQL 查询：

```mysql
SELECT customer_id, COUNT(*)
FROM orders
GROUP BY customer_id
```

这个查询会返回每个客户的订单数量，其中 customer\_id 是分组依据，而 COUNT(\*) 则计算每个客户对应的订单行数。



##### CAST 小数

**入了`CAST`函数**：这个函数在SQL中用于将一个数据类型转换为另一个数据类型。在这里，我用它来确保在计算过程中使用的数值被当作浮点数处理。这是因为在许多SQL系统中，整数除以整数会得到整数结果。通过将整数转换为浮点数，我们可以得到精确的小数结果，而不是被截断的整数结果。



#### Views:Named Queries 视图对关系表


```mysql
CREATE VIEW view\_name 
AS select\_statement

CREATE VIEW Redcount
AS SELECT B.bid,COUNT(\*) AS scount
FROM Boats2 B,Reserves2 R
WHERE R.bid=B.bid AND B.color='red'
GROUP BY B.bid
```
选择Boat2 中bid 列 并计算 每个bid 的对应的总行数，指定涉及查询的表，指定

SELECT bname,scount
FROM Boats2 B,
(SELECT B.bid,COUNT(\*)
```mysql
FROM Boats2 B,Reserves2 R
WHERE R.bid = B
```
#### NULL 值及其对sql查询的影响
字段值有时候是未知的：在数据库中，有时候某些字段的值是未知的，或者不存在
，SQL使用NULL 来表示这样的情况，而且无论是数字字符串还是其他什么的都可以用NULL来表示
NULL 的存在复杂化了很多问题： 选择谓词(WHERE 语句)在使用 WHERE 语句来过滤数据时，需要特别处理NULL值，因为NULL与任何其他的值的比较都不会返回True.
聚合函数:在使用如SUM AVG 等聚合函数的时候NULL 的值通常会被忽略，但是对于COUNT 函数，`COUNT(*)`函数会计算包含 NULL的行数，而`COUNT(column)`函数只会计算非NULL 的数量
NULL非常自然地来自于外连接

在SQL中，NULL是一个特殊的值，你不能用普通的等于(=)或不等于(\<\> 或 !=)运算符来与之比较。你需要使用IS NULL或IS NOT NULL来检查一个字段是否为NULL。

如果你想返回referee\_id不等于2，或者是NULL的所有客户名称，你应该使用IS NULL或者\<\>运算符，并且使用OR来结合这两个条件。

所以你的查询应该这样写：

```mysql
SELECT name 
FROM Customer C
WHERE C.referee_id <> 2 OR C.referee_id IS NULL;
```

这条SQL语句将返回所有referee\_id不等于2的记录，以及所有referee\_id为NULL的记录。

#### 数据库管理系统（DBMS)的不同层级
![传输速度与大小的关系.png](https://s2.loli.net/2024/03/25/3NxbA9FaCldJhqE.png)

![数据库的不同层级.png](https://s2.loli.net/2024/03/25/CH4iYbBNRm1K9OD.png)
最上层是 SQL Client，这是用户与 DBMS 交互的界面。
然后是 Query Parsing & Optimization，这一层解析查询并进行优化，以提高执行效率。
接下来是 Relational Operators 层，它执行 SQL 查询中的关系操作，如连接（joins）和选择（selects）。
紧接着是 Files and Index Management 层，这一层负责数据的物理存储和索引的维护。
最底层是实际的 Database，这是数据被存储的地方。
\(img)
\(img)
 seek time (moving arms to position disk head on track)
• \~2-3 ms on average
• rotational delay (waiting for block to rotate under head)
• \~0-4 ms (15000 RPM)
• transfer time (actually moving data to/from disk surface)
• \~0.25 ms per 64KB page
寻找和旋转的状态比较长，传输的时间几乎可以忽略不计
固态硬盘又称为ssd

#### 细粒度读取（Fine-grain reads）：
这指的是可以以较小的数据块（例如4-8KB）进行读取操作，这使得读取操作可以针对小量数据进行快速访问。
 READ: transfer “page” of data from disk to RAM.
#### 粗粒度写入（Coarse-grain writes）：
相比于读取，写入操作通常在较大的数据块上执行，例如1-2MB。这意味着每次写入涉及的数据量比读取时多。
 WRITE: transfer “page” of data from RAM to disk.

###### 有限的擦除次数（Erasures before failure）：

NAND闪存单元在出现故障之前只能被擦除有限次数，通常是2千到3千次。因此，为了延长SSD的寿命，通常采用“磨损均衡”（wear leveling）策略，即在驱动器内部移动频繁写入的数据块，以防止某个区域过度磨损。

###### 写放大（Write amplification）：

在某些情况下，实际写入到NAND闪存的数据量会比应用程序请求的多，这是由于写操作和垃圾回收（garbage collection）机制导致的。为了在内部优化和重新组织数据存储，SSD可能需要移动和重写数据，这可能导致额外的写入操作。
SSD比磁盘快100倍左右
同样的钱，买到的磁盘存储量大概是SSD的10倍左右

###### “下一个”块概念：

同一轨道上的连续块，首先是这些，然后是同一柱面（cylinder）上的块，然后是相邻柱面上的块。
通过在磁盘上连续地按照“下一个”来安排文件页面，这样可以最小化寻道（seek）和旋转延迟（rotational delay）。
对于顺序扫描，可以预先获取（pre-fetch）多个块。
读取大量连续的块。

#### 高扇出(HIgh fan-out)
通常用于描述树形数据结构，这里的“扇出”指的是树中每个节点的子节点数量。高扇出意味着每个节点有许多子节点，这样的数据结构可以有效减少搜索、插入和删除操作所需的层数。“扇出”（fan-out）是指一个节点（无论是树结构中的节点还是逻辑网络中的节点）有多少个子节点或者分支。简单来说，就是从一个节点出发，可以直接到达多少个下一级节点。

在一棵搜索树中，高扇出意味着每个内部节点有很多子节点。这减少了树的高度，从而可以减少访问特定记录时需要访问的节点数量，这对于加速查找和检索操作非常有帮助。在关系数据库中，例如，一个高扇出的B+树索引会有很多指向数据页的指针，这样可以在很少的磁盘I/O操作中快速找到数据。\(img)

#### 固态硬盘（SSD）中的闪存技术（特别是NAND闪存)
细粒度读取（4-8K读取）和粗粒度写入（1-2MB写入）。
在故障之前只能进行大约2000到3000次擦除操作，所以需要移动频繁写入的单元以分散穿戴，这个过程被称为“磨损均衡”（wear leveling）。
写入放大：由于使用了大的存储单元，因此需要重新组织存储以管理磨损和垃圾回收。
#### Block 和 Page
Block = Unit of transfer for disk read/write
Book says 4KB
Page : block很多情况下的同义词，“page”是a block size chunk of RAM

数据库文件（DB FILE）：是由多个页面（pages）组成的集合，每个页面包含了多个记录（records）。
数据库管理系统（DBMS）的高层API：
插入（Insert）、删除（delete）或修改（modify）记录。
通过记录ID（record id）获取特定记录。这里的记录ID是一个指针，它编码了页面ID（pageID）和该页面上的位置（location on page）。扫描（Scan）所有记录，可能会附加一些条件来检索记录。
跨越性：
这种数据库文件可以跨越多个操作系统文件甚至不同的机器。
或者直接使用“原始”磁盘设备。

##### FIle of Pages of Records

数据库文件（DB FILE）：是由多个页面（pages）组成的集合，每个页面包含了多个记录（records）。
数据库管理系统（DBMS）的高层API：
插入（Insert）、删除（delete）或修改（modify）记录。
通过记录ID（record id）获取特定记录。这里的记录ID是一个指针，它编码了页面ID（pageID）和该页面上的位置（location on page）。
扫描（Scan）所有记录，可能会附加一些条件来检索记录。
跨越性：
这种数据库文件可以跨越多个操作系统文件甚至不同的机器。
或者直接使用“原始”磁盘设备。

###### 多种数据库文件结构

- **无序堆文件（Unordered Heap Files）**
  - 记录随意放置在各个页面上
  
- **聚集堆文件（Clustered Heap Files）**
  - 记录和页面被分组
  
- **排序文件（Sorted Files）**
  - 页面和记录按排序顺序排列
  
- **索引文件（Index Files）**
  
  - B+ 树、线性哈希等
  
  - 可能包含记录或指向其他文件中的记录
  
    <a href="https://sm.ms/image/3dzNKslea4I1g7j" target="_blank"><img src="https://s2.loli.net/2024/04/01/3dzNKslea4I1g7j.png" ></a>
  
  ##### **聚集索引**:
  
  - 在聚集索引中，数据文件的物理顺序与键值的顺序相匹配。这意味着基于索引键组织数据记录，记录在磁盘上是连续存储的。
  - 聚集索引中的“heap file order”不需要完美，意味着虽然记录大体上是有序的，但不是严格按顺序排列的。它更像是一种性能上的优化。
  - 通过聚集索引检索数据的成本会根据索引是否聚集而有很大差异。因为聚集索引通常能够减少数据检索的I/O操作，特别是对于范围查询。
  
  ##### **非聚集索引**:
  
  - 非聚集索引与数据文件的物理顺序无关。索引中的条目指向数据存储在文件中的位置，但这些位置可以在文件中的任意地方。
  - 由于数据记录和索引键的物理顺序不匹配，检索数据可能需要更多的I/O操作，因为每次索引查找都可能指向不同位置的记录。
  - <a href="https://sm.ms/image/3p2ebgWKdio8vqw" target="_blank"><img src="https://s2.loli.net/2024/03/29/3p2ebgWKdio8vqw.png" ></a>





在这个成本模型分析中，我们关注的是数据库或文件系统中的磁盘I/O操作。主要参数包括：

- **B**：文件中的数据块数量。

- **R**：每个块包含的记录数量。

- **D**：读取或写入磁盘块的平均时间。

- DBMS架构中最底层的部分，负责在磁盘上管理空间，确保数据页正确映射、加载和保存。它的主要目的是：

  - 将数据页映射到磁盘上的特定位置。
  - 从磁盘加载页到内存中。
  - 将更改后的页保存回磁盘，并确保写入操作被正确执行。

  DBMS的更高层级将调用这一层来完成以下任务：

  - 读取或写入单个数据页。
  - 在逻辑层面上分配或释放数据页。

  当数据库执行扫描操作时，它需要访问存储在磁盘上的数据块。

  <a href="https://sm.ms/image/sjgBrKyGueHdYT8" target="_blank"><img src="https://s2.loli.net/2024/04/01/sjgBrKyGueHdYT8.png" ></a>

##### 把 堆文件当成列表

<a href="https://sm.ms/image/9hIHkEnAfL8RJ27" target="_blank"><img src="https://s2.loli.net/2024/04/01/9hIHkEnAfL8RJ27.png" ></a>



### 哈希索引（Hash Index）：

- **哈希函数**：哈希索引使用一个哈希函数，该函数接收一个输入（例如，一个字段的值）并产生一个固定大小的哈希值。
- **适用场景**：它非常适合于等值查询，即那些使用`=`, `!=`, `IN`等操作符的查询，因为它可以直接计算出数据行的存储位置。
- **限制**：不适用于范围查询，如使用`>`, `<`, `BETWEEN`等操作符的查询。此外，哈希索引不支持顺序数据检索和快速的数据排序。

##### Sort Hash

1. **“Rendezvous”**:
   - 排序可以用作不同数据集之间同步点的一种手段，确保数据以预期的顺序进行处理或合并。
2. **Eliminating duplicates (DISTINCT)**:
   - 排序通常是去除重复项的预处理步骤。当数据排序后，相同的记录会排列在一起，这使得检测和删除重复项变得更容易。
3. **Grouping for summarization (GROUP BY)**:
   - 在数据库查询中，排序用于`GROUP BY`操作，以便将相同或相关的数据聚集在一起进行汇总或其他聚合操作。
4. **Upcoming sort-merge join algorithm**:
   - 排序是合并连接算法的前提条件之一，它要求两个数据集在进行合并连接前先进行排序。
5. **Ordering**:
   - 排序用于保证数据的顺序性，这在很多应用中非常关键，比如时间序列分析，其中数据必须按照时间顺序进行处理。
6. **Sometimes, output must be ordered (ORDER BY)**:
   - 在SQL查询和其他数据处理任务中，最终的输出有时需要按特定顺序排列，例如按相关性递减顺序返回结果。
7. **First step in bulk-loading tree indexes**:
   - 在构建树形索引结构（如B树）时，将数据先排序可以大大加快批量加载数据的速度。

关于处理大数据量（例如100GB）的排序问题，当可用内存（例如1GB）远小于数据量时，存在的问题是：

- 虚拟内存为什么不行？
  - 虚拟内存可以让你的操作系统模拟更多的内存，但是它是通过不断地在磁盘和RAM之间交换数据来实现的。对于排序操作来说，这会造成大量的磁盘I/O操作，导致效率极低，特别是当涉及到大量数据时。
  - 磁盘I/O速度远远慢于RAM。因此，频繁的交换会极大地降低性能，导致排序操作耗时长。
  - 在大数据量的情况下，更有效的做法是使用特定的算法，如外部排序，这种算法设计用来在有限的内存中高效地处理大量数据的排序。

1. **主线程运行函数f(x)处理一对I/O缓冲区中的数据**：
   - 这里的主线程专注于执行计算任务，例如处理输入缓冲区的数据。
2. **第二个I/O线程在后台并行地排空/填充未使用的I/O缓冲区**：
   - 另一个线程（或进程）负责管理I/O操作，这样就可以在数据被主线程处理的同时，预加载或写入下一批数据。
   - 这种方法的优点是可以减少等待I/O操作完成的时间，从而提高整体性能。
3. **并行处理的可行性**：
   - 这里提到并行处理是可行的，因为通常计算和I/O操作可以同时进行，它们之间在硬件层面上是解耦的。
4. **I/O处理通常值得拥有自己的线程**：
   - 这是因为I/O操作（特别是磁盘操作）通常涉及等待，而拥有独立的线程可以在等待时释放CPU资源给其他任务。
5. **当主线程准备好处理新的缓冲区时，就执行交换操作**：
   - 一旦主线程处理完当前的缓冲区，它就可以与I/O线程交换缓冲区，开始处理新的数据集，而I/O线程则可以开始处理或填充另一个缓冲区。



- **缓冲页（Buffer Pages）**：
  - 缓冲页是指算法可以用来存储中间数据的内存页数量。在这种情况下，B表示可用的缓冲页数。
- **排序运行（Sorted Runs）**：
  - 排序运行是指在每次读取时可以完全载入到缓冲区并排序的数据页的序列。

该算法按以下步骤执行：

1. **Pass 0（初始通道）**：
   - 使用B个缓冲页对文件进行初始读取。每次读取B页数据，对它们进行排序，形成一个“排序运行”。
   - 这样会产生 N / B 个排序运行，每个运行包含B页数据（N是总页数）。
2. **后续通道（Pass 1, 2, ...）**：
   - 在后续的通道中，每次会合并 B-1 个排序运行。这是因为需要留出一个缓冲页用于输出合并结果。
   - 在每一通道中，取B-1个排序运行的第一页载入缓冲区，执行合并操作，并将结果输出到存储设备。当这些页被处理完后，继续读取下一页，直到所有的运行都合并完成。



### B树索引（B-Tree Index）：

- **树结构**：B树索引是一种自平衡的树结构，支持对数据的顺序访问，适合于大量数据的快速插入、删除和搜索操作。
- **适用场景**：它非常适合范围查询和顺序查询，可以很快地找到大于或小于某个值的所有记录，也适合用于数据排序和分组。
- 

表被编码为文件，这些文件是页面的集合。
页面目录提供页面的位置和空闲空间的信息。

对于数据库文件而言，头页可能包含以下信息：

- **文件的类型**：例如，它是存储数据的表文件还是索引文件。
- **页面大小**：文件中每一页的大小。
- **页的数量**：文件中总共有多少页。
- **空闲页的列表**：记录文件中哪些页是空闲的，可以用来存储新的数据。
- **页的分配信息**：记录哪些页已经被分配用来存储数据。

###### 页面目录包含多个头页（Header Pages）

- 记录数（Number of records）：页面中记录的数量。
- 空闲空间（Free space）：页面内未被使用的空间量。
- 下一个/最后一个指针（Next/last pointer）：可能用于链表结构中，指向页面序列中的下一个或最后一个页面。
- 位图（Bitmaps）、槽表（Slot Table）：这些结构用于管理页面内的记录，例如位图可能用于标识哪些记录槽（slot）是空的或被占用的，槽表则记录每个记录的位置。

1. **更复杂的选择**:

   - **2维盒子**: 通常用于定义地图边界，比如查询在一个特定的地图区域内的数据。
   - **2维圆形**: 例如，查询在某个地标（如帝国大厦）周围2英里内的数据。

2. **常见的多维索引**:

   - **R-tree** 和 **KD-tree** 是支持空间数据查询的索引结构，它们可以处理多维空间数据。
   - 但是在使用这些结构时要注意“维数诅咒”——随着维度的增加，数据点在多维空间中的稀疏性会导致效率降低。

3. **近邻查询**:

   - 用于查询离某个点最近的一组数据点，例如找出距离某个地标最近的10家餐厅。

4. **正则表达式匹配、基因组字符串匹配**:

   - 适用于文本搜索和生物信息学应用的索引，可以快速匹配复杂的模式和序列。

   

   ##### 复合搜索键

   定义：复合搜索键是基于多个列的，如 $\left(k_1, k_2, \ldots, k_n\right)$, 它与查询相匹配，如果：

   - 查询包含 $m$ 个 $(m \geq 0)$ 等值条件的合取（AND连接的条件），形如：
   $k_1=<$ val1 $>$ AND $k_2=<$ val2 $>$ AND $\ldots$ AND $k_m=<$ valm $>$
   - 此外, 查询还可能包含至多一个范围条件, 形如:
   $k_{m+1} \mathrm{op}<\mathrm{val}>$, 其中 $\mathrm{op}$​ 是比较运算符 '< '或 '>”。
   
   **为什么这会“匹配”？**

   - 当对复合键进行查询时，可以在等值条件上执行查找操作来确定范围的起始点。
   - 然后可以扫描叶节点处连续的数据条目来：
     - 满足第 m+1 个条件
     - 如果没有第 m+1 个条件，则扫描与前m个条件相匹配的所有条目



- **Age = 31 & Salary = 400**：有效查询，因为它指定了复合键的两个条件。
- **Age = 55 & Salary > 200**：有效查询，指定了第一个键的确切值，并为第二个键给出了一个范围。
- **Age > 31 & Salary = 400**：这不是有效的复合键查询，因为它首先指定了第一个键的范围，对于复合键 `<Age, Salary>` 的查询，“**Age > 31 & Salary = 400**” 这个条件在复合键索引中的查找不是最高效的。

- 搜索索引成本 $=\left(\log _F(B R / E)+1\right) \times D$

其中：
- BR: 总记录数（Block Records）。
- E: 每个叶节点的记录数（Entries per leaf）。

・ $\mathrm{F}:$ 扇出, 即每个索引节点的子节点数。
- D: 磁盘 $1 / O$ 成本（在这种情况下，每次 $1 / O$ 操作的成本假设为 1 ）。

公式中的 $\log _F(B R / E)$ 计算的是, 给定每个叶节点包含E条记录, 并且每个内部节点有 $F$ 个子节点时, 从根节点到叶节点所需的层数。公式中的 +1 是因为需要考虑访问根节点的成本。然后将这个数乘以每层的 $1 / O$ 成本（在这个例子中是D）。

1. **关系模型（Relational Model）**： 在关系模型中，每个表的每条记录都有固定的类型，意味着每个字段都定义了数据类型（如整数、字符串等）。
2. **系统目录（System Catalog）**： 系统目录存储了数据库的模式（Schema），即所有表结构的定义，包括表名、列名、数据类型等信息。因为类型信息存储在系统目录中，记录本身就无需重复存储这些信息，这样可以节省空间。可以认为目录本身也是一个表，它包含关于其他表的信息。
3. **目标（Goals）**：
   - 记录在内存和磁盘上的存储应该是紧凑的，这意味着它们不应占用多余的空间。
   - 访问记录的字段应该快速。这很重要，因为数据库操作的性能很大程度上依赖于如何快速地读取和写入数据。
4. **简单情况：固定长度字段（Easy Case: Fixed Length Fields）**： 如果所有字段都是固定长度的，记录的格式就很简单，因为每个记录的大小都是一样的，我们可以很容易地计算出任何一个字段在记录中的位置。
5. **有趣情况：可变长度字段（Interesting Case: Variable Length Fields）**： 对于包含可变长度字段（如字符串）的记录，处理起来更复杂，因为每条记录的大小可能都不一样。对这样的记录，通常需要额外的结构来存储长度信息或者使用分隔符来区分不同的字段。

1. **单表（Single Table）**： 首先，讨论的是单个表的情况。这是指数据库中的一个表，通常在物理存储中被组织为一系列的“页”。
2. **数据库文件（DB FILE）**： 数据库文件是由许多“页”组成的集合，每一页包含了许多记录。这些页是存储记录的基本单元，每个页可以包含多个记录。
3. **DBMS的高层API（API for higher layers of the DBMS）**： 数据库管理系统提供API来实现对数据的读取和更新：
   - 读取（Reads）
     - **获取特定记录**：可以通过记录的ID（record id）来定位并获取特定的记录。记录ID通常是一个指针，包含页ID（pageID）和该页上的位置（location on page）。
     - **扫描所有记录**：可以扫描表中的所有记录，并可能根据某些条件过滤记录。
   - 更新（Updates）
     - 包括插入（insert）、删除（delete）和修改（modify）记录。
4. **跨多个操作系统文件和甚至跨机器的抽象**： 这个抽象层能够跨越多个操作系统文件，甚至是不同的机器，这意味着DBMS能够管理分布在多个文件甚至多台计算机上的数据。

#### Heap File

## 需要区别一下ISAM树和B+树，这后面的是B+树
> ISAM树和B+树都是数据库和文件系统中用于数据存储和检索的数据结构。

### ISAM树（Indexed Sequential Access Method）

ISAM树是一种文件组织技术，它提供了一种在磁盘上存储记录的方式，使得既可以顺序访问也可以随机访问。ISAM的核心思想是将文件分为两个部分：一个是顺序存储的数据区，另一个是一个或多个索引区。

- **数据区**：数据按顺序存储，每个记录可以是固定长度也可以是可变长度。
- **索引区**：包含了指向数据区中记录的指针，索引区本身可以有多层，每一层的索引指向下一层，直到指向数据区的记录。

ISAM的一个限制是索引结构是静态的，当数据集增长时，可能需要重新组织文件来维持性能。

### B+树

B+树是一种自平衡的树数据结构，它维持数据在树中的排序，使得查找、顺序访问、插入和删除等操作都可以在对数时间内完成。B+树广泛应用于数据库和文件系统中，因为它们非常适合大量数据的存储和检索。

B+树的特点包括：

- **节点分裂**：当一个节点中的条目数超过了预设的最大数量（通常由磁盘页的大小决定），它会分裂成两个节点，保持树的平衡。
- **所有数据指针在叶子节点**：B+树的所有数据指针都位于叶子节点中，非叶节点只存储键值作为索引。这意味着实际的数据值是分离的，只有树的叶子节点包含数据指针。
- **叶子节点链接**：B+树的叶子节点按键值顺序链接，这为顺序访问提供了高效的途径。

B+树相较于其他树结构（如二叉树、B树等）的优势在于其高度平衡和页读取效率，使得它特别适用于磁盘存储和大型数据库系统。
For Heap FIle
Insert always appends to end of file堆文件是一种没有排序的文件，新记录总是添加到文件的末尾
For Sorted File

#### cost of
Find Key 8:
P(i) 表示特定键在第 $\mathrm{i}$ 页的概率is $\frac{1}{B}$
T(i) Number of pages touched if key on page i is i因为是堆文件, 所以如果键在第 $\mathrm{i}$ 页, 你必须访问 $\mathrm{i}$ 页
B: The number of data blocks 数据块的数量
R: Number of records per block 
D:Average time to read/write disk block

$T(i)$ 表示如果键在第 $\mathrm{i}$ 页, 需要访问的页数。因为是堆文件, 所以如果键在第 $\mathrm{i}$ 页, 你必须访问 $\mathrm{i}$ 页来找到它。
期望的页数是所有可能情况下, 每种情况页数的概率加权和, 即 $\sum_{i=1}^B T(i) \cdot P(i)$ 。这里, 因为 $P(i)$ 对于所有 $\mathrm{i}$ 都是相同的, 它简化为 $\frac{1}{B} \cdot \sum_{i=1}^B i$ 。
最后的公式展开后是一个等差数列求和公式, $\sum_{i=1}^B i$ 从 1 加到 $\mathrm{B}$, 结果是 $\frac{B(B+1)}{2}$ 。乘以前面的 $\frac{1}{B}$就得到 $\frac{B+1}{2}$ 
这个结果表示查找任何键值时, 期望访问的页数平均是 $\frac{B+1}{2}$ 。但是由于在实际应用中, $\mathrm{B}$ 通常非常大, 所以 $\frac{B+1}{2}$ 可以近似为 $\frac{B}{2}$​ 。

对于 颜色的解释：
浅蓝色（第一张图的顶部节点和第二张图的中间节点）代表初始查找阶段，即开始时读取的页面。
白色节点代表随后的中间步骤，即查找过程中可能会触及的页面。
黑色节点（第一张图中的底部节点）代表查找的最后阶段或最坏情况，即需要检查所有页面才能找到所需的键。

#### 插入4.5堆文件和已排序文件

- 插入新记录（如键值4.5）通常很简单，你只需将新记录“粘贴”在文件末尾。
- 成本是“2\*D”，这可能代表着两个磁盘I/O操作，一个是读取最后一页，以确定是否有足够的空间进行追加，另一个是写操作，将新的记录追加到页中。
- “为什么是2？”这个问题可能是在询问为什么成本是两倍的磁盘I/O操作，答案就在于需要进行一次读取和一次写入。

#### 删除4.5 堆文件和已排序文件

- 删除一个记录首先需要找到记录的位置，这可以通过二分搜索算法以对数时间复杂度来完成，成本为 "log2B"。
- 找到记录后，你会在页面中删除该记录，这将在页面中留下一个空隙。如果你想要维护文件的连续性和有序性，可能需要将后面的所有记录都向前移动一个位置来填补这个空隙。这个过程的成本是页面的一半（即删除点后的所有页面），乘以2（因为每个页面需要读取和写入），所以是 "2 \* (B/2)"。

"N" 通常指的是执行某项操作所需要的磁盘页数。

I/O 成本会远远大于CPU成本和RAM的成本

#### 两种访问API

1. **通过记录ID获取（fetch by recordId）**：这是一种定位和检索特定记录的方式，需要使用页ID（pageId）和槽ID（slotId）来准确找到记录。
2. **扫描（scan）**：这是一种迭代访问文件中记录的方式，它从某个页面开始，顺序地访问文件中的所有记录。

**数据条目**：存储在索引中的元素。对于这次讲解，假设数据条目是一对（k, recordId），这里的“k”是关键词，而“recordId”是记录标识符。

**指向堆文件中的记录的指针**：这表示索引中的数据条目包含了指向实际记录在堆文件中位置的指针。

**修改**：索引的设计要支持快速插入和删除操作，以便于维护数据的一致性和时效性。





$$log_F{B}$$



Pages touched on average 
average case binary search
第一项 1 (1 / B) 表示在第一次读取时找到目标的概率是 1 / B。
第二项 2 (2 / B) 表示如果第一次没有找到，那么第二次找到目标的概率是 2 / B（因为范围缩小了一半，所以概率翻倍）。
类似地，3 (4 / B) 和 4 (8 / B) 分别代表第三次和第四次读取时找到目标的概率。

```
		Heap File             | Sorted File
```


## 从这里开始应该是 B+ 树了

#### B+树
内部节点至少是半满的
```
- d ≤ # entries ≤ 2d
```
Why not in sequential order?
```
Data pages allocated dynamically
叶子节点（数据页）没有按顺序编号。在B树中，数据页是根据插入和删除操作动态分配的，因此它们的编号可能不会反映任何特定的顺序。这种动态分配允许B树在维持平衡的同时动态地调整大小
```
d 值怎么算？在图中 每个page 最多有5个指针，2d+1=5 所以d = 2 **(max fan-out = 2d + 1)**
\(img)
[oiwiki上的解释]
对于B树和B+树，平衡意味着所有的叶子节点都位于同一层。
**始终保持平衡：**B+树是一种自平衡树，无论何时插入或删除操作，它都会通过分裂或合并节点来保持平衡。这保证了所有操作的最坏情况下时间复杂度都是对数级别的。
**支持高效的插入和删除：**B+树设计成可以高效处理插入和删除操作，因为它会在操作后自动重新平衡
**在根部增长而非叶子：**与其他树结构不同，当需要增加树的高度时，B+树会在根部增长，而不是在叶子节点增长。这意味着所有的叶子节点始终保持在同一层。

###### 比起B 树的一些不同:

所有的叶子节点都包含全部键值信息，并且按键值的顺序构成了一个链表。
叶子节点可能包含实际的数据记录，或者是数据记录的指针。
内部节点（非叶子节点）仅用作索引，它们包含了子节点的最大（或最小）键值作为搜索参考。

对于B+树而言 如果说它的阶数是d,意味着
每个非根节点至少有 d个分支（或子节点），而根节点至少有两个分支，除非它是叶子节点。每个非根节点最多可以有 2d 个分支。

叶子结点

#### "Fan-out"
指的是一个节点能有多少个子节点。在B树中，高"Fan-out"意味着一个节点可以有许多子节点，这可以减少树的高度，从而提高数据库查询的效率。

###### 占用不变量（Occupancy Invariant）：

>  半满...?有些点可以不是半满的比这个要少，把这样的页面取消掉。参考redefine部分

图片下方解释了B+树的一个关键性质，即每个内部节点至少部分填充。这意味着每个内部节点至少有d个关键字，并且最多有2d个关键字。这里的d是树的阶数，它决定了树的最大扇出（即一个节点的最大子节点数），这里是2d+1。这个性质保证了树的平衡和搜索效率。

节点关键字的数量：在B+树中，内部节点（不包括叶子节点）的关键字数量通常是子节点数量减去1

#### Splitting leaf node

<a href="https://sm.ms/image/j2TodykBDCzeG6n" target="_blank"><img src="https://s2.loli.net/2024/03/26/j2TodykBDCzeG6n.png" ></a>



<a href="https://sm.ms/image/1AVWEu9atS5gMoF" target="_blank"><img src="https://s2.loli.net/2024/03/26/1AVWEu9atS5gMoF.png" ></a>

<a href="https://smms.app/image/eY7m9fsKuvC5pyH" target="_blank"><img src="https://s2.loli.net/2024/03/26/eY7m9fsKuvC5pyH.png" alt="image.png"></a>





<a href="https://sm.ms/image/8RlWfK7pUw3ObyZ" target="_blank"><img src="https://s2.loli.net/2024/03/26/8RlWfK7pUw3ObyZ.png" ></a>

#### Insert

Heap file 
* Stick at the end of file新记录被插入到文件的末端
* Cost = `2*D`Read last page,append write(一次键盘I/O 找到插入位置，比如文件末尾）另一次I/O将新记录写入磁盘
Sorted file 
* Find location for the record Cost = $log_2_{BD}$
#### 插槽目录
- ## 位于页面的底部(Footer)
- 包含一个指向可用空间的指针
- 对于每个目录，插槽目录存储了记录的长度以及指向记录开始的位置的指针
- 这些长度和指针是按照逆序 存储的，意味着最后一个记录的信息会首先存储到插槽目录中
#### 记录标识符
- 记录ID 在插槽表中的位置，通常由页码和记录在页中的索引号组成，例如第二页，第四条操作
#### 删除操作
如果需要删除一个记录

**紧密打包记录(packed)：**
所有的记录都是固定长度，并且在页面中紧密排列，没有空隙。
由于记录长度固定，所以记录间不需要额外的指针或分隔符。
**记录标识符（Record ID）：**
每条记录的ID通常由页面ID和该记录在页面中的位置（即“位置在页面”）组成。
由于所有记录长度相同，所以可以通过记录的序号乘以固定长度来计算出它在页面中的偏移量（Offset）。
**添加记录：**
新记录可以轻松地添加到页面的末尾，因为所有记录都有相同的长度，所以只需要在最后一个记录后面追加新记录即可。
**删除记录：**
对于删除操作，有几种处理方式。一种可能的方式是标记记录为已删除，然后将其留在原地，但这会导致页面中出现“空洞”。另一种方式是实际移动后面的记录来填补被删除记录的空间，这样可以保持记录紧密打包，但这种方式成本较高，因为需要移动大量数据。
在某些系统中，可能会使用一个标记位来指示记录是否被删除，或者维护一个空闲列表，列出已删除的记录的位置，以便将来重用

#### 阶数 

> B+树的典型阶数是1600

对于一个阶数为 $m$ 的 $B+$ 树:
每个内部节点最多可以有 $m$ 个子节点。
每个内部节点（除了根节点）最少应该有 $\lceil m / 2\rceil$ 个子节点, 这里的 $\lceil x\rceil$ 表示对 $x$ 向上取整。
根节点至少应有两个子节点, 除非它是叶节点, 即树中仅有一个节点的情况。
所有叶子节点都在同一层上, 即树的底层。
每个节点（除了叶子节点和根节点）至少要有 $\lceil m / 2\rceil-1$​​ 个关键字。关键字的数量总是比子节点的数量少一个。
每个叶子节点包含有关键字和对应的数据指针或数据记录, 而内部节点则含有关键字和指向子节点的指针。

#### 填充因子（fill-factor）

是67%，这意味着每个节点的利用率为67%。填充因子是节点使用的空间与节点总空间的比例。 是经验结果。

#### h-容量关系

- 如果树的高度为 1 , 那么它可以直接指向 2144 个数据记录。
- 如果树的高度为 2 , 那么每个树的顶层节点可以指向 2144 个子节点, 而这些子节点又各自指向 2144 个数据记录, 总容量就是 $2144^2$ 。
- 类似地, 如果树的高度为 3 , 那么顶层节点指向 2144 个子节点, 这些子节点又各自指向2144个子节点, 而这些子节点再各自指向2144个数据记录, 总容量就是 $2144^3$ 。

这样, 树的容量可以通过取分支因子的高度次幂来计算。在幻灯片中, 它列出了两个高度下的记录数:
- 高度1: $2144^2=4,596,736$ 条记录
- 高度2: $2144^3=9,855,401,984$ 条记录

### Bulk loading of B+ 树

##### 如果有很多要插入的数据这样做效率其实很低

如果我们想要在一个大表上建立索引，直接调用插入操作（即一次插入一个记录）效率不高。原因包括：

- 随机顺序插入（例如上面的字符串CLZARNDXEKFWIUB）可能会导致不平衡的树，影响性能。
- 每次插入都需要从树的根节点开始搜索合适的插入位置，这会随着树的增长导致效率下降。
- 这种插入方式会造成叶子节点和内部节点大多数时间都只填充了一半，即填充因子较低，这意味着空间利用率不高。

- 经常需要从根节点开始搜索。
- 叶子节点和内部节点大多是半空的。
- 随机修改页面会导致缓存效率低下，因为缓存系统通常依赖于数据局部性原理，而随机访问模式破坏了这种局部性。

##### Bulk loading 是在干什么：

- 在构建B+树时，批量加载首先对输入记录进行排序。这样，当你插入记录时，它们已经是有序的。
- 这种方法可以直接填充叶节点页面到一个特定的填充因子，比如3/4满，这样确保了高效的空间利用率。
- 在填充叶节点时，同时更新父节点，直到树的所有层都被正确填充。
- 这样可以保持树的平衡，并且减少了需要进行的I/O操作，因为一次可以在内存中处理多个连续的记录。

所以说我们需要：为大量数据构建B+树索引时，批量加载数据比重复单个插入操作更有效。批量加载通常是顺序的，可以提高空间和时间效率，因为它减少了搜索操作的次数，提高了节点的填充率，并且更好地利用了缓存。在实际操作中，这通常涉及到将所有数据先排序，然后以一种能最大化数据连续性和减少节点分裂的方式构建B+树。这样可以得到一个填充因子高、更加平衡的树，提高了查询和遍历的效率。

##### 更加智能的bulk-loading 

- 对输入的记录按键进行排序。
- 提到了将使用一种良好的基于磁盘的排序算法，这可能指的是像外部排序这样的算法，它能处理的数据量超出了内存的容量。
- 填充叶子页到某个填充因子，例如3/4，然后更新父节点，直到父节点也填满为止。

1. **对输入记录排序**:
   - 将所有输入记录按键值进行排序（如1*, 2*, 3*, 4*等），保证了数据的顺序性。
2. **填充叶节点页至一定的填充因子**:
   - 例如，可以选择填充到3/4满。
   - 然后更新父节点，直到它也变满。
   - 如果父节点满了，则进行分裂操作，创建新的节点。
3. **总结批量加载的优势**:
   - 多次插入（Option 1）:
     - 这种方法较慢。
     - 它无法保证叶子节点在存储介质上连续存储，这对性能不利。
   - 批量加载（Option 2）:
     - 在构建过程中减少了I/O操作，因为可以一次性处理更多有序的数据。
     - 叶子节点将被顺序存储，而且它们之间是相互链接的，这对范围查询特别有利。
     - 可以控制页面上的填充因子，从而优化存储效率和查询性能。

#### 固定长度记录格式
字段类型相同，文件中所有记录的字段类型是相同的
字段类型信息通常单独存储在系统的目录（systen Catlog)中 不会在每个记录中反复存储

#### Record Formats: Variable Length
What happens if field are variable length?
比如那些无法预知确切长度的数据，比如人名，地址等等
记录的存储 与固定的长度记录不同，变长记录会为每个字段分配固定的空间。相反，每个字段的实际使用的空间与他的内容长度相匹配，这样的好处是节约空间，不会为未使用的部份分配空间
Single Record Insert and delete 在任何给定的操作中，仅仅插入或删除单个记录，这简化了插入和删除操作的过程，因为不需要考虑多记录的的事物管理或者一致性问题
Equality selection - exactly only one match
这个假设说明在进行等值查询，预计只会有一个确切的匹配结果，被查询的字段具有唯一性约束，例如主键或具有唯一索引的字段


\(img)
Conquer
Rehash(conquer)
Read partitions into RAM hash table one at a time ,using hash function f’n hr

```
Each bucket contains a small number of distinct values
```
Then read out RAM hash table bucket and write to disk
```
Ensuring that duplicate values are contigious
```
#### Bitmap
还是会有空间浪费的情况

#### 一次硬盘 读写操作的总时间

1.	寻道时间（Seek Time）：
   •	这是磁头臂移动到磁盘上正确的轨迹以访问数据块所需的时间。平均寻道时间大约是2-3毫秒。
2.	旋转延迟（Rotational Delay）：
   •	一旦磁头臂定位到正确的轨迹，就需要等待数据块旋转到磁头下方。这个时间取决于硬盘的转速。对于15000转每分钟（RPM）的硬盘，旋转延迟大约是0-4毫秒。这个范围意味着，如果恰好数据块位于磁头正下方，则没有延迟；如果刚刚错过，则可能需要一整圈的时间才能再次到达磁头下方。
3.	传输时间（Transfer Time）：
   •	这是实际上从磁盘表面读取或向磁盘表面写入数据的时间。这个幻灯片上显示，传输一个64KB的数据页大约需要0.25毫秒。

• Disk are a mechanical anachronism (slow!)

• SSDs faster, **slow relative to memory**, costly writes

#### 可变长度
放在原始地方，记录id比较希望是稳定的

#### 一般来说，当我们建立索引时候我们会考虑以下内容:

- **查询支持**：索引能够支持哪类查询。不同的索引结构可能对不同的查询类型提供支持。例如，一些索引可能更适合范围查询，而其他的可能更适合精确匹配查询。
- **搜索键的选择**：搜索键的选择会影响哪些查询可以利用索引来加速。搜索键应当是频繁查询的属性，选择得当可以显著提升查询效率。
- **数据条目存储**：如何存储索引中的数据条目会影响索引的性能。例如，数据条目是否直接存储了记录，或者只是引用了记录的存储位置。
- **可变长度键技巧**：在索引中处理可变长度的键可能会影响性能，需要特别的技术来有效地管理和搜索这样的键。
- **索引与堆文件和排序文件的成本模型**：创建和维 护索引是有代价的，需要对比索引的使用成本与堆文件或排序文件的使用成本，以确定最有效的数据存储和检索方法。

#### 复合搜索键（composite search key）

- 至少包含 0 个或更多形式为 $k_1$ = $\text{<val>1}$且 k_2 = $\text{<val>2} $且 …… 且 k_m = $\text{<val>m}$ 的等值子句的联接（conjunction），以及
- 至多包含 1 个附加的范围子句，形式为 AND km+1 op <val>*A**N**D* *k**m*+1 *o**p* <val>，其中 op*o**p* 是 {<,>}{<,>} 中的一个。



#### 匹配原理：

这个复合键如何与查询“匹配”呢？它通过字典顺序（lexicographic order）中的查找和扫描来实现：

- 可以在等值子句的连接上进行查找, 以找到范围的开始。
- 可以扫描叶子节点处连续的数据条目:
- 以满足第 $m+1$ 个子句,
- 或者如果没有第 $m+1$ 个子句, 则扫描整个与前 $m$ 个子句匹配的数据集。

#### Data Entry Storage Intro

1. **索引中数据的表示形式**：(页面还是单独文件？)
   - 索引可以存储实际数据或者指向数据的指针。
   - 存储实际数据的索引称为包含索引（covering index），它们可以加快查询速度，因为不需要访问表中的数据。
   - 存储指向数据的指针的索引则需要查询索引以获取指针，然后再访问表中的数据行。
2. **数据文件中的存储方式**：
   - 数据可以与索引“聚集”存储或“非聚集”存储。
   - 聚集索引意味着表中的数据按索引的排序存储。只能有一个聚集索引，因为你不能同时以多种方式物理排序同一数据集。
   - 非聚集索引和数据的物理存储顺序无关，它们仅提供指向数据的指针。
3. **对性能的影响**：
   - 数据的存储方式会极大地影响数据库的性能。
   - 聚集索引通常提供了更快的数据访问速度，因为相关数据通常物理上存储在一起。
   - 非聚集索引可能会导致更多的磁盘I/O操作，因为数据可能分散存储在不同的位置。



![Index_B_.jpg](https://s2.loli.net/2024/03/25/OlsepnPDqBgQ8Km.png)

（搜索键，[uid,页面偏移量]）

[uid,页面偏移量] = 相应指针

![Alternative_2_Index.jpg](https://s2.loli.net/2024/03/25/VhHRNj5iUYQgIr3.png)



![Indx.jpg](https://s2.loli.net/2024/03/25/zuDhMk38GlnYU1c.png)

更加紧凑，能提高空间利用率，搜索更加高效?每一个叶子能跨多个数据

举个例子，如果索引是建立在“年龄”这一列上的，那么对于关键字“30”来说，RID列表会包含数据库中所有30岁的人的记录的位置信息。这样，当查询数据库寻找所有30岁的人时，数据库管理系统（DBMS）就可以直接使用这些RID来快速找到这些记录，而无需遍历整个表。

#### 前缀键压缩（Prefix Key Compression

1. **在叶子节点上压缩：** 当索引的叶子节点包含变长的键值时，可以通过仅存储键值中不同的部分来减少空间需求。比如，如果有多个键值以“Sarah”开头，只需完整存储第一个键值“Sarah Lee”，而后面的键值可以存储为“Manning”，“Zhu”等，省略掉共同的前缀“Sarah”。
2. **分裂时确定最小分割前缀并向上复制：** 当一个叶子节点满了并需要分裂时，系统会找到一个分割点，这个点是基于前缀压缩之后的最小键值。然后，将这个最小的分割前缀“拷贝”或者“提升”到父节点，以便保持索引结构的有序性。

Zip 都是一样的 作为共同前缀

![B_treecomplexity.jpg](https://s2.loli.net/2024/03/25/qZ7HNQAkGiD59IB.png)

- 存储数据时采用按引用存储（Alternative 2），这意味着不是将数据直接存储在索引结构中，而是存储指向数据实际存储位置的指针。
- 使用聚集索引时，堆文件页面（Heap file pages）通常填充到2/3。这样做是为了优化性能，因为堆文件在初始时已经排序好。这个数值是经验
- “Fan-out（F）”表示索引中每个节点的子节点数量，它通常是相当大的。这是因为索引页面包含很多的<key, pointer>对，其数量通常和记录数（R）的数量级相同。
- 假设索引是静态的，意味着索引不会因为数据的增加或删除而改变结构。

要理解这些概念，先要明白数据库索引的工作原理：

- **聚集索引**：表中的数据行的物理顺序与键值的逻辑（索引）顺序相同。由于聚集索引决定了数据的物理顺序，一个表只能有一个聚集索引。
- **非聚集索引**：索引中的键值的顺序与硬盘上的物理存储顺序不同，通常需要额外的指针来指向数据的实际位置。

叶子结点的数量 = B*R/E

logF (BR/E) 树的高度 +1 （根节点）



#### First Relocate metadata to folder

插槽页面：槽表，保留页面开始的信息
圆圈：指向新记录可以开始的地方
元信息（Metadata）是关于数据的数据，它描述了其他数据的属性，使得我们能够理解和管理这些数据。元信息为数据提供了上下文，例如，它可以告诉我们数据的来源、格式、内容、创建时间和目的等信息。

当在分隔页中插入一条记录时，通常会遵循以下步骤：

放置记录：在页面的空闲空间中放置记录本身。
创建指针和长度对：在页面的槽目录（Slot Directory）中，为这条记录创建一个指向记录起始位置的指针以及记录长度的对。槽目录是页面底部的一部分，它跟踪页面上每条记录的位置和大小。
更新空闲空间指针：插入记录后，页面的空闲空间会减少，所以需要更新指向页面上当前空闲空间起始位置的指针

#### Externel Merge Sort Algorithm
- Let M denote the number of blocks in the main memory buffer availavle for sorting
#### First stage : A number of sorted runs are created
Each run is sorted but contains only some of the records of the relation
i = 0
repeat 
```
read M blocks of the relation,or the rest of the relation,whichever is smaller
sort the in-memory part of the relation
write the sorted data to run file R_i
i = i+1
```
until the end of relation

#### Second Stage
The runs are merged 
The total number of runs,N is less than M so that we can allocate one block to each run and have space left to hold one block of out put
\(img)

\(img)
\(img)
#### Double Buffering
Main thread runs f(x) on one pair I/O bufs
2nd thread drains/fills unused I/O bufs in parallel
```
Why is parallism available
```

##### ONE BUFFER PAGE RESERVED FOR OUTPUT:

#### Index Assumption

<a href="https://sm.ms/image/aWzNPEDt5R1UIZ9" target="_blank"><img src="https://s2.loli.net/2024/04/11/aWzNPEDt5R1UIZ9.png" ></a>



### Relational Algebra

S1 - S2:删除 S1 中 与 S2 不同的部分，保留 S1独特的部分

<a href="https://sm.ms/image/SwFBvxhu4TKepzC" target="_blank"><img src="https://s2.loli.net/2024/04/10/SwFBvxhu4TKepzC.png" ></a>





<a href="https://sm.ms/image/4v76bi2N8Y1MQDl" target="_blank"><img src="https://s2.loli.net/2024/04/10/4v76bi2N8Y1MQDl.png" ></a>



关系数据库中谓词（条件）求值顺序的简单改写。这种改写是基于选择操作（σ）的结合律和交换律，说明了我们可以更改两个谓词（条件）求值的顺序而不改变查询的最终结果。

谓词通常代表着数据库查询中的条件表达式。当你有两个谓词（比如 expr1 和 expr2）应用于某个关系R时，你可以先按一个顺序应用它们，然后更改顺序，而结果仍然是相同的。

表达式展示了以下等价关系：

1. $\sigma_{\operatorname{expr} 1 \wedge \operatorname{expr} 2}(R)$
2. $\sigma_{\operatorname{expr} 1}\left(\sigma_{\operatorname{expr} 2}(R)\right)$
3. $\sigma_{\operatorname{expr} 2}\left(\sigma_{\operatorname{expr} 1}(R)\right)$

第1个表达式使用了逻辑与（∧）来组合两个谓词，并且作用在关系R上。这表示只有当记录同时满足expr1和expr2时，它才会被选择出来。

第2个和第3个表达式显示了谓词求值的两个可能的顺序。你可以先对关系R应用expr2，然后对结果应用expr1，或者反过来。根据选择操作的结合律，这两个过程是等价的，最终将产生相同的结果集。

这个原理在优化数据库查询时是很有用的，因为某些情况下，改变谓词的顺序可以提高查询的效率。例如，如果一个谓词比另一个更能缩小结果集的大小，那么先执行它可能更高效。

假设在合并过程中，我们会保留一个缓冲页专门用于输出。例如，在一个B路合并中，除了要处理的B个数据页之外，还需要一个额外的缓冲页用于存储合并的结果。
$$
\sigma_{\text {age }>40}(R 1 \bowtie S 1)
$$

这个表达式表示的是首先对 R1 和 S1 表进行自然连接，然后在结果集上应用选择操作来找出年龄大于 40 岁的记录。



这里有两个关系表:
- R: 记录船只的预订情况，包括水手ID (sid)，船只ID (bid)，和预订日期 (day)。
- $\mathrm{S}$ : 记录水手的详细信息, 包括水手ID (sid), 水手姓名（sname）, 评级（rating）和年龄 (age)。

幻灯片中提供了一种方法来编写这个查询:
1. $\pi_{\text {sname }}(S)-\pi_{\text {sname }}\left(\sigma_{\text {bid }=103}(R \bowtie S)\right)$

这个查询的逻辑是:
- 先找出所有预订了编号为 \#103 船的水手（通过选择 $R$ 表中 bid=103 的记录并与 $S$ 表进行自然连接)。
- 然后从所有水手的名单 ( $S$ 表) 中减去这些水 $\downarrow$ 灼名单, 留下那些没有预订过 \#103 船的水手的名字。

- 关系代数是一组将关系映射到关系的操作符的集合。
- 它是操作型的，意味着你可以明确指定操作的顺序。
- 它是一组封闭的操作符集合，可以混合和匹配。
- 关系代数易于操纵、改写和简化。
- 非常强大，可以封装很多SQL的功能。

基本操作包括：

- σ (选择)
- π (投影)
- × (笛卡尔乘积)
- ∪ (并集)
- - (差集)

1. 当Requestor完成对页面的使用后，它必须：
   - 如果页面被修改，设置一个脏页标志（dirty bit）。这通常用于表示页面自从被读入内存以来已被修改，因此如果页面被替换出内存，其内容需要写回硬盘。
   - 尽快取消固定（unpin）页面。取消固定意味着告诉内存管理系统该页面不再被该进程保持在内存中，可以被替换出去。
     - 为什么要取消固定？因为这允许内存管理系统回收和重用内存，如果一个页面长时间被固定，它就不能被回收，这可能会导致资源利用不足。
     - 如果不尽快取消固定会怎样？这可能导致内存不能被有效利用，其他需要内存的进程可能因为找不到可用页面而受阻。
2. 同一个页面可能会被多次请求：
   - 使用固定计数（pin count）来跟踪页面被固定的次数。每当页面被进程请求保持在内存时，固定计数增加。
   - 当固定计数归零时（即没有任何进程需要该页面保持在内存中时），该页面成为可能的替换候选。
3. 在页面被替换时，一致性控制（CC）和恢复可能会执行额外的输入/输出操作：
   - 这里提到的“Write Ahead Log protocol”是一种确保事务数据一致性和恢复的机制，用于在系统故障时恢复数据库或文件系统的一致状态。更详细的内容会在之后讲到。

### 1. 请求者完成后的操作

- **设置脏位（Dirty Bit）**：如果页面（page）被修改了，请求者需要设置脏位。脏位是一个标志，用来指示页面自从被读入缓存（cache）以来是否被修改过。如果页面被修改了（即脏了），那么在它被替换出缓存并写回磁盘之前，需要先写回（flush）到磁盘以确保数据的一致性。
- **解除固定（Unpin the page）**：页面被请求到缓存中后，通常会被“固定”（pin），以避免它在使用中被替换出去。请求者在完成页面的使用后应该尽快解除对它的固定。解除固定是为了使页面可以被页面替换算法考虑替换出去，特别是在内存紧张时。
  - **为什么需要解除固定？**：解除固定使得页面能够再次成为替换算法的候选对象，从而允许更有效地利用缓存空间。如果页面长时间被固定，会导致缓存空间无法被高效利用，可能会导致缓存命中率下降，从而影响整体性能。
  - **如果不及时解除固定会怎样？**：如果页面长时间保持固定状态，它将不可被替换，这可能会导致缓存空间的浪费，其他需要被缓存的页面无法进入缓存。这会增加缓存缺失率，导致更多的磁盘I/O操作，降低系统性能。

### 2. 页面的固定计数

- 页面在缓存池中可能会被多次请求，因此使用**固定计数（pin count）**来跟踪页面被固定的次数。固定一个页面时，其固定计数会增加（pin_count++）。
- 一个页面只有在其固定计数为0时（即没有被固定），才能被考虑作为替换的候选者（即“可被替换的（replacement candidate）”）。

### 3. 替换时的额外I/O操作

- **并发控制（Concurrency Control, CC）和恢复（Recovery）**：在页面被替换出缓存时，为了确保事务的原子性和持久性，可能需要进行额外的I/O操作。这通常涉及到使用**预写日志（Write Ahead Log, WAL）协议**等恢复技术，以确保在发生故障时能够恢复到一致的状态。在替换页面前，必须确保所有必要的日志信息已经被写入到日志文件中，这是为了确保在发生故障时，可以通过日志来回滚或重做操作，恢复数据库的一致性。



##### 一个LRU的例子

你可以看到一系列页面（Page 1 至 Page 7），它们被组织在一个环形结构中，这通常被比喻为一个时钟。每个页面都有一个对应的标记，可能是一个勾（√）或一个方块。勾通常表示页面最近被引用过（Reference bit 设置为 1），而方块则表示页面没有被最近引用过（Reference bit 设置为 0）。红色的图钉表示页面被固定（Pinned），即不应该被置换。

图中有一支指针（通常被称为时钟指针），它指向当前考虑进行置换决策的页面。在本例中，指针指向“Page 5”。

下面是处理页面请求的步骤，图中请求读取“Page 7”：

1. 如果请求的页面已经在内存中（如图中的Page 7），则不需要页面置换。
2. 当请求页面在内存中且未固定时，操作系统会设置该页面的引用位，表示它最近被访问过。
3. 如果请求的页面不在内存中或被固定，则时钟指针会移动到下一个页面，并检查它的引用位。
   - 如果引用位被设置，操作系统会清除它，并移动指针到下一个页面。
   - 如果引用位未设置，且页面未固定，那么该页面将被置换，新的页面会被加载到内存中的这个位置。
4. 如果发生页面置换，新页面的引用位被设置，并且通常也会设置固定位，以防止它立即再次被置换。

![LRU_replacement.jpg](https://s2.loli.net/2024/03/25/P2Yd5UT4sROycbN.png)

##### LRU的伪代码

```C++
page *clock_request_page(int &clk_hand, int pg_num) {
    retval = NULL;
    while (retval == NULL) {
        current = frame_table[clk_hand];
        // the happy case: replace current page
        if (current.pin_count == 0 && current.refbit == 0) {
            if (current.dirty == 1) {
                write_page(fi.page, frames[clk_hand]);
            }
            read_page(pg_num, frames[clk_hand]);
            retval = frames[clk_hand];
            current.dirty = 0;
            current.pin_count = 1;
            current.refbit = 1; // referenced!
        }
        // second chance: unset reference bit
        else if (current.pin_count == 0 && current.refbit == 1) {
            current.refbit == 0;
        }
        // else pin_count > 1, so skip
        clk_hand += (clk_hand + 1) % MAX_FRAME; // advance clock hand
    }
    return retval;
}

```



##### 为什么LRU会导致 0% 的cache hit ?

使用最近最少使用（LRU）缓存替换策略时，如果进行大量的顺序扫描操作，可能会导致0%的缓存命中率。这是因为LRU策略会在缓存满了之后，替换掉最久未使用的数据。在顺序扫描中，数据库可能会连续读取数据，每次读取都涉及到不同的数据页。

图片中的文字解释了当你有 $B$ 个缓冲区（buffers）和一个文件包含 $N$ 页（pages），且 $N$ 大于 $B$ 时的缓存命中情况。具体来说:
- 第一遍 $(\mathrm{N}$ 次尝试）：0 次命中
- 接下来的 ( $B-1)$ 遍, 每遍有 $B$ 次命中
- 然后的 (N-B) 遍, 每遍有 (B-1) 次命中
- 接下来的 (B-1) 遍, 每遍有 $B$ 次命中
- 以此类推......

最后, 它给出了一个命中率的极限公式, 即:
In limit: $\frac{(B(B-1)+(B-1)(N-B))}{(N(N-1))}=\frac{(B-1)}{(N-1)}$ hit rate

**到每次“命中”都表示一个页面请求能够在缓冲区中被直接找到，而不需要从更慢的存储（例如硬盘）中重新加载该页面。**

#### Buffer Pool

Buffer pool: Large range of memory, malloc’ed at DBMS server boot time (MBs-GBs)

### Clock算法工作原理：

1. **页面（Page）**：表示内存中可以被替换的一个固定大小的数据块。

2. **时钟指针（Clock Hand）**：这是一个指针，按顺序指向页面，类似于时钟的秒针。

3. **引用位（Reference Bits）**：每个页面都有一个引用位，当页面被访问（读取或写入）时，这个位会被设置为1。

4. 置换（Replacement）

   ：当需要一个新页面被载入内存但没有空闲页面时，时钟算法会检查时钟指针指向的当前页面。

   - 如果该页面的引用位是1，这意味着页面最近被使用过，时钟算法会清除这个位（置为0），并将时钟指针移动到下一个页面。
   - 如果引用位是0，这表示页面最近没有被使用，时钟算法会选择这个页面进行置换。

### Reference Bits的作用：

- **跟踪页面使用情况**：引用位用于跟踪每个页面是否在最近一段时间内被访问过。每次页面被访问时，操作系统会设置引用位。
- **决定页面是否被置换**：当需要置换时，如果引用位被设置为1，页面会被暂时保留，引用位被清零；如果引用位为0，页面会被视为置换候选。
- **减少性能成本**：使用引用位允许系统不必记录每个页面精确的访问时间，从而减少了算法的开销。

"pin count" 值反映了一个页面在缓冲池中被固定（pin）的次数。如果一个页面的 "pin count" 为2，这意味着有两个不同的进程或查询请求固定了该页面，以便进行读取或写入操作。页面被固定时，它不能被置换出缓冲池，这样就确保了当页面正在被使用时，不会因为页面置换算法而被意外移除。



### LRU算法：

LRU算法会移除最长时间未被使用的页面。它基于一个假设，即最近被使用的页面在未来也很可能被使用，而长时间未被使用的页面可能在未来一段时间内也不会被使用。

**优点**：

- LRU能很好地利用时间局部性（temporal locality），即如果一个页面最近被访问过，那么它在不久的将来可能再次被访问。

**缺点**：

- 实现成本较高，因为它需要记录每个页面最后访问的时间，或者维护一个页面的使用顺序列表。

### Clock算法：



**被clock hand 指到的实际上是我们要赶走的倒霉蛋**

##### 关于 reference bit:（Approximately how recently a page is used)

- 如果引用位是1，这意味着页面自上次检查以来被访问过，时钟算法会将引用位清零（设置为0），并将时钟指针移动到下一个页面。
- 如果引用位是0，这意味着页面自上次检查以来未被访问，这个页面就成为了替换的候选对象。

例子：

<a href="https://sm.ms/image/Nlhmw4IdJKkiyaz" target="_blank"><img src="https://s2.loli.net/2024/04/07/Nlhmw4IdJKkiyaz.png" ></a>

- 时钟指针当前指向页面2。
- 页面2的固定计数大于0，意味着它正在被使用，因此算法不能选择这个页面来替换。
- 由于页面2不能被替换，时钟指针将会移动到下一个页面，继续查找固定计数为0的页面来替换。

Clock算法是一种近似LRU的更经济的策略。它通过一个循环列表（时钟结构）和引用位来跟踪页面的使用情况。

**优点**：

- 更低的成本，因为它不需要记录每个页面的具体访问时间，只需要检查和更新引用位。

**劣势**：

- 它只是近似LRU，因为它可能不会精确地移除最近最少使用的页面。如果所有页面的引用位经常被设置，Clock算法可能需要多个循环才能找到可替换的页面。
- <a href="https://sm.ms/image/E61vIVaJBw7QDOe" target="_blank"><img src="https://s2.loli.net/2024/04/07/E61vIVaJBw7QDOe.png" ></a>

### LRU 替换策略

LRU是一种常见且直观的页面置换策略，它基于这样一个理念：如果一个数据页在最近被频繁访问，那么它在未来也有可能被访问。所以，这个策略会替换掉那些最长时间未被访问的页面。

**优点**：

- 利用了时间局部性原则，对于经常访问的页面（“热”页面）表现良好。

**为什么可能成本高昂**：

- 实现真正的LRU策略需要不断地跟踪每个页面的最后使用时间，当需要置换页面时，需要在所有页面中找到最早的“最后使用”时间（即找到最小的最后使用时间）。在数据结构中执行“find min”操作可能很昂贵，尤其是当页面数量很大时。
- 若要高效地找到最小值，通常需要使用优先级队列或堆（如二叉堆）数据结构，这样每次插入或删除操作都需要O(log n)的时间复杂度。对于大规模系统，这可能意味着显著的处理开销。

### 他们表现不佳的情况：

- 如果系统访问模式是均匀的，即所有页面都被近似均等地访问，那么LRU和Clock算法可能不会比其他更简单的算法（如先进先出FIFO）表现得更好。
- 如果系统有一个很长的连续页面访问模式，使得每个页面都在时钟指针回到它之前被访问（即，所有页面的引用位在时钟指针回到它们之前都被设置为1），那么Clock算法可能会降低效率，因为它需要多次循环才能找到一个可替换的页面。
- 如果存在一个非常大的数据集被频繁地扫描，这会导致LRU算法中几乎所有页面都被视为“最近使用过”的，这样最有用的数据可能会被替换出去，尽管它们可能立即会再次需要。



##### “Scratch disk”

一词在计算机术语中通常指的是用于临时存储数据的磁盘空间。在处理需要大量读写操作的任务，如视频编辑、大型计算或排序任务时，这部分磁盘空间尤其重要。在两路外部归并排序中，scratch disks提供了必要的额外存储空间，用于临时保存数据，因为这些数据不能完全存储在RAM中。简单来说，scratch disks就像是工作台，暂时存放那些正在处理或将要处理的数据。在上下文中，提到的两个scratch disks各自拥有远超过文件F所需的N个blocks的存储空间，确保了在排序过程中有足够的空间来存放临时文件和数据。

#### Two way external merge sort 

<a href="https://sm.ms/image/uZbVcQytCRzUMg4" target="_blank"><img src="https://s2.loli.net/2024/03/29/uZbVcQytCRzUMg4.png" ></a>



1. 输入文件: 初始的未排序文件。
2. Pass 0:
- 将文件分为多个1页大小的runs, 并且排序每个run。
3. Pass 1:
- 将排序好的1页runs两两合并, 形成更大的2页runs。
4. Pass 2:
- 再次合并, 这次是2页runs合并成4页runs。
5. Pass 3:
- 最终将4页runs合并成8页runs, 此时, 如果文件大小允许, 整个文件就被排序了。

## Cost of External Merge Sort

<a href="https://sm.ms/image/8Ju7MgxYFZzeoDI" target="_blank"><img src="https://s2.loli.net/2024/03/29/8Ju7MgxYFZzeoDI.png" ></a>



这个 除数依次递减1

**Streaming Partition (divide)**: 这是一个处理数据的方法，使用哈希函数 hp*h**p* 将数据流式传输到不同的磁盘分区。这里的重点在于：

- **哈希函数 hp\*h\**p\* 的作用**: 这个函数用于决定哪些记录应该流向哪个分区。具有相同哈希值的记录将被发送到同一个分区，这确保了数据的组织方式，使得后续的处理更加高效。
- **分区内容**: 每个分区将包含一组值的混合，这些值是根据哈希函数的结果确定的。因此，虽然每个分区可能包含不同的记录，但这些记录在某种程度上是有序的，因为它们拥有相同或相似的哈希值。
- **流式算法创建磁盘分区**: 这个算法会随着数据的读取，持续地创建分区并将它们写入磁盘。这是一种逐步处理的方法，可以适应大量的数据。
- **分区“溢出”到磁盘通过输出缓冲区**: 当内存中的输出缓冲区满了，数据会被“溢出”到磁盘上的分区。这就是说，缓冲区中的数据会被写到磁盘上，然后缓冲区会被清空以便可以填入新的数据进行接下来的处理。

**ReHash (conquer)**: 这一步是指重新处理之前分区的数据以进一步组织和优化。它包括以下几个步骤：

1. **读取分区到RAM中的哈希表**: 这里，你会一次读取一个分区到内存中的哈希表中。这个哈希表使用不同的哈希函数 hr*h**r* 来组织数据，这可以是之前用于分区的哈希函数的细化或变体。
2. **每个桶包含少量不同的值**: 哈希表的目的是减少每个桶（bucket）中的冲突，这样，每个桶都将包含少量不同的值。
3. **读出RAM哈希表的桶并写入磁盘**: 接下来，处理完的数据会从内存中的哈希表桶中读出，并连续写回磁盘。
4. **确保重复值是连续的**: 这个过程保证了数据在磁盘上是连续存储的，特别是相同或相似的值。这对于后续的数据访问和处理是有益的，因为它减少了磁盘访问的随机性和提高了访问效率。

<a href="https://sm.ms/image/v68LayIuls93bD1" target="_blank"><img src="https://s2.loli.net/2024/03/29/v68LayIuls93bD1.png" ></a>

<a href="https://sm.ms/image/zigJl8tyEh1DZrb" target="_blank"><img src="https://s2.loli.net/2024/03/29/zigJl8tyEh1DZrb.png" ></a>

- 表的大小: 幻灯片问的是, 在两次过程中我们可以哈希多大的表? 答案是 $B(B-$ 1 )。这意味着如果我们在第一次过程中创建了 B-1 个分区, 每个分区可以包含最多 $\mathrm{B}$ 页数据, 那么我们可以处理的总数据大小为 $B(B-1)$ 页。
- 假设: 这个计算假设哈希函数能够均匀地分布记录。

如果表更大怎么办?
- 递归分区: 如果我们有一个更大的表，我们可以递归地对其进行分区和哈希处理。在第一次过程中，使用哈希函数 $h_p$ 创建分区，然后在“征服”（Conquer）过程中,使用另一个哈希函数 $h_r$ 对这些分区进行哈希处理, 以便进一步优化它们的存储。

流程:
- 分区 (Divide) : 使用哈希函数 $h_p$ 对原始数据进行分区。
- 征服 (Conquer) : 使用哈希函数 $h_r$ 处理每个分区的数据。

并行化我！哈希阶段 1 (Parallelize me! Hashing Phase 1):
- 第一阶段 (Phase 1): 这个阶段的目标是将数据在多台机器间进行分布（也称为 shuffle)，这是通过以下步骤实现的:
- 使用哈希函数 $h_n$ 来决定每条记录应该被发送到哪台机器。
- 在数据被扫描的同时, 它会被流式传输出去到网络上, 即数据在被读取的同时即发送到目标机器。
- 独立的哈希函数 $h_n$ : 为了决定记录的目的地, 这里提到了使用“另一个独立的哈希数 $h_n$ ”。这意味着这个哈希函数与之前用于初始分区的哈希函数不同, 可能是专设计用来在这个分布式环境中平衡负载和最小化数据倾斜。

这种并行化方法是分布式计算中常用的模式, 特别是在大数据处理框架中, 如 MapReduce。在MapReduce中, "shuffle"阶段正是用于在map（映射）阶段和 reduce（归约）阶段之间重新分配数据, 确保每个reduce任务接收到正确的数据子集以进行进一步的处理。通过哈希函数保证了数据分配的均匀性和高效性。



**哈希的优点**:

- 用于去除重复项时，哈希的效果随着值的数量而扩展，这意味着它可以有效地处理大量的数据项。
- 在第一次过程（通常指的是哈希过程）中就可以删除重复项，这是在对数据进行哈希分区时的一个自然结果。
- 与排序相比，哈希在项目数量增加时表现得更好。
- 在并行案例中，哈希能够轻易地均匀地进行数据的分发（shuffle）。

**排序的优点**:

- 如果最终的输出需要排序，那么排序是一个很好的选择。
- 排序对重复值或者“不好”的哈希函数不敏感。这意味着即使存在大量的重复数据或哈希函数未能均匀分布数据，排序仍然能够有效地工作。

这张幻灯片显示的是，根据不同的需求和数据特性，排序和哈希可以作为不同场景下数据处理的有力工具。如果数据需要去重，并且数据可以被均匀分布，哈希可能是更好的选择。而如果最终结果需要有序，或者数据有很多重复，排序会是更合适的选择。在分布式计算环境中，这些技术的选择对于性能和资源利用率有直接的影响。

## Lec 9 RelAlg

SQL语言的关键系统特性是它的声明性。用户不需要指定数据检索的具体步骤；他们只需要声明他们感兴趣的结果的结构。这样做允许更复杂的查询被简单地写出，并且数据库系统的优化器可以优化查询，以便以最有效的方式执行。

#### Unary

• Unary Operators: on **single relation**

• **Projection** (p): Retains only desired columns (vertical)

• **Selection** (s ): Selects a subset of rows (horizontal)

• **Renaming** ( 𝜌 ): Rename attributes and relations.



######  Binary 

• **Union** ($\cup$ ): Tuples in r1 or in r2.

• **Set-difference** ( — ): Tuples in r1, but not in r2.

• **Cross-product** ( $\times$​ ): Allows us to combine two relations.

###### Compound

• Compound Operators: common “*macros*” for the above

• **Intersection** ( ∩ ): Tuples in r1 and in r2.

• **Joins** ( ⋈𝜃 , ⋈ ): Combine relations that satisfy predicates

##### Compound Operator: Join

1. **Theta Join (⨝θ)**: 这是基于逻辑表达式θ的连接，θ可以是任意复杂的条件。例如，`R.x < S.y`或者`R.name = S.name AND R.age > S.age`都可以作为θ的例子。
2. **Equi-Join**: 这是theta join的一个特例，其中θ是一系列的等式条件。也就是说，它只比较相等性，例如`R.id = S.id`。
3. **Natural Join (⨝)**: 这是equi-join的一个特例，它自动在两个表共有的所有列上执行连接。也就是说，它会找到所有在两个表中有相同名称的列，并在这些列上进行匹配，而不需要明确指定连接条件。

## Lec 10 join 

**排序合并连接的成本（Cost of Sort-Merge Join）:**

1. **排序阶段（Sorting Phase）:**
   - 这个阶段涉及到两个数据集R和S。首先，数据从磁盘读入内存中，然后使用可用的缓冲区（Buffers）进行排序，生成排序后的子序列（Runs），最后将它们写回磁盘。
   - 成本计算公式: `Cost: Sort R + Sort S + (|R|+|S|)`，其中|R|表示数据集R的记录数，|S|表示数据集S的记录数。排序成本是指将所有记录读入内存并进行排序，然后写出的IO操作数。
2. **合并阶段（Merging Phase）:**
   - 在这个阶段，已排序的Runs将被合并。使用B-1个输入缓冲区（Input Buffers）来读取Runs，并使用一个输出缓冲区（Out Buffer）来存储合并后的结果，最终将结果写回磁盘。
   - 成本中的最后一项“|R| * |S|”是最坏情况下的合并成本。这种情况很不可能发生，因为它意味着每个来自R的记录都与S中的每条记录相匹配，导致非常高的输出结果。但是，幻灯片指出这是不太可能的。

**缓冲区大小问题（Question about buffer size）:**

- 问题是为了能在两个通道中排序R和S，缓冲区需要多大？
- 假设缓冲区大小B大于等于max(|R|, |S|)的平方根。这个条件确保了R和S可以在两次传输中被完全排序。

**例子计算（Example Calculation）:**

- 假设|R|是1000，|S|是500，则公式如下： `4*1000 + 4*500 + (1000 + 500) = 7500`
- 这个计算表明，进行排序和合并所需的总IO操作数是7500。

在这里，“B buffers”表示在排序时可用的缓冲区数量，“B-1 input buffers”表示在合并时用于输入的缓冲区数量，外加一个输出缓冲区。

**最坏情况（Worst case）:**

- 最坏情况下，幻灯片提问：最坏的情况是什么？
- 这可能指的是每条记录都需要进行比较和合并，导致IO成本急剧上升到|R| * |S|的程度。

这个分析对于数据库管理员在执行查询优化时非常有用，尤其是在处理大型数据集时，理解和最小化IO成本非常关键。



#### Simple Nested Loops Join

简单嵌套循环连接是最直观的连接算法之一，它对于每个来自关系R的记录r，遍历关系S中的所有记录s，并检查它们是否满足连接条件θ。如果满足，就将记录对<ri, sj>添加到结果集中。

```java
foreach record r in R do
    foreach record s in S do
        if θ(ri, sj) then add <ri, sj> to result buffer

```

其中，θ(ri, sj)代表连接条件，例如ri.id = sj.id。

幻灯片中还提供了执行这个连接的成本估算。成本计算使用之前幻灯片中提到的符号，其中`[R]`表示存储关系R所需的总页数，`p_R`表示每页的记录数，`|R|`表示关系R的总记录数，同样的符号也用于关系S。

成本估算公式为：`[R] + |R||S|`。这里的思路是，我们首先要读取关系R中的每一页（`[R]`），对于R中的每一条记录，我们需要遍历S中的所有记录。所以，成本是关系R的页数加上关系R的记录数乘以关系S的记录数。



**成本表示（Cost Notation）:**

- **[R]:** 存储表R所需要的页数。
- **p_R:** 表R每页的记录数。
- **|R|:** 表R的基数，即记录的数量。
- 公式 |R| = p_R * [R] 用于计算表R中的总记录数。

**例子（Examples）:**

1. **Reserves 表：** 这是一个预订表，包含如下字段：

   - sid: 整数类型，表示学生ID。
   - bid: 整数类型，表示书籍ID。
   - day: 日期类型，表示预订日期。
   - rname: 字符串类型，表示预订人的名字。
   - 该表的信息如下：
     - [R]=1000，意味着存储这个表需要1000个页。
     - p_R=100，表示每个页有100条记录。
     - |R|=100,000，表示整个表有100,000条记录。

2. **Sailors 表：** 这是一个水手表，包含以下字段：

   - sid: 整数类型，表示水手ID。

   - sname: 字符串类型，表示水手的名字。

   - rating: 整数类型，表示水手的评级。

   - age: 实数类型，表示水手的年龄。

   - 该表的信息如下：

     - [S]=500，意味着存储这个表需要500个页。
     - p_S=80，表示每个页有80条记录。
     - |S|=40,000，表示整个表有40,000条记录。

     ```pseudocode
     For Cur in {R, S} // 对于每个表R和S
         For page in Cur // 遍历表中的每个页
             Read page into input buffer // 将页读入输入缓冲区
             For tup in page // 对于页中的每个元组
                 Place tup in output buf hashp(tup.joinkey) // 根据元组的连接键的哈希值将元组放入相应的输出缓冲区
                 If output buf full then // 如果输出缓冲区满了
                     flush to disk partition // 将输出缓冲区的内容写到磁盘对应的分区中
         Flush output bufs to disk partitions // 将所有输出缓冲区的内容写到磁盘对应的分区中
     
     ```

     <a href="https://sm.ms/image/HjalGpqEQC9eyvP" target="_blank"><img src="https://s2.loli.net/2024/04/07/HjalGpqEQC9eyvP.png" >

     

     </a>

   - 不同形状代表不同属性

   1. **构建阶段（Build）**：

      - 从输入的分区中（如Partition 1），选择一组记录来构建哈希表。
      - 在这个阶段，会使用所有的记录中的键（例如星号标记的记录）来构建哈希表，这个哈希表占用了(B-2)个缓冲区（Buffers）。
      - 哈希表是用于快速查找和匹配键的数据结构。

   2. **探测阶段（Probe）**：

      - 接下来，其他分区（如Partition 2）中的记录会被用来探测这个哈希表。
      - 在探测阶段，我们会查找每条记录的键是否在哈希表中存在。如果存在，这意味着找到了与之相匹配的记录，这样就可以执行连接操作。
      - 对于每个探测操作，通常会使用一个缓冲区来读取分区中的数据，然后在哈希表中查找匹配的项。

      **哈希连接特别适用于大型数据集，因为它能够有效地将磁盘I/O操作最小化。在构建和探测阶段，它通过局部性原理优化内存的使用：哈希表被保存在内存中，这样就可以快速地进行查找和匹配操作**

1. **简单哈希连接**（Naïve Hash Join）：
   - 这种方法要求所有的R（一个表或数据集）都能放进哈希表中，即R*R* < B，这里R*R*代表R的大小。
   - 这种方法的成本相对较低，因为它只需要一个遍历（一次pass），但这只适用于当数据集R足够小，能够完全放入内存中。
2. **Grace哈希连接**（Grace Hash Join）：
   - Grace Hash Join处理较大的数据集，即R*R*可以大于B的情况，但需要数据集R和S的大小平方小于B的平方，即R*R*+S*S* < B²。
   - 它是两遍的算法（two-pass），在图表中表示为成本更高，因为需要两个遍历来完成连接。
3. **混合哈希连接**（Hybrid Hash Join）：
   - 这是一种介于Naïve和Grace之间的算法，旨在根据具体情况调整使用的策略。
   - 它的目的是减少Grace算法中的一些I/O成本，但通常来说它比较难以调整（Tricky to tune）。

## Lec 12

 Query Optimization II:

• Costing and Searching

1. **索引I在主键上的匹配选择**：
   - 成本计算为`Height(I) + 1`，用于B+树索引。
   - 这里的`Height(I)`指的是B+树索引的高度，`+1`表示在叶节点中找到具体的记录。
2. **聚集索引I匹配选择**：
   - 成本为`(NPages(I) + NPages(R)) * selectivity`。
   - `NPages(I)`是索引页的数量，`NPages(R)`是表记录所在页的数量，`selectivity`是选择性，表示满足条件的数据比例。
3. **非聚集索引I匹配选择**：
   - 成本为`(NPages(I) + NTuples(R)) * selectivity`。
   - `NPages(I)`是索引页的数量，`NTuples(R)`是表中记录的数量，`selectivity`同样表示满足条件的数据比例。
4. **文件的顺序扫描**：
   - 成本为`NPages(R)`。
   - 简单地说，这是扫描整个表的成本，`NPages(R)`是表中页的数量。

#### 左深计划

- 左深计划在关系的顺序、每个叶子操作符的访问方法以及每个连接操作符的连接方法方面不同。
- 使用N次遍历（如果有N个关系需要连接）来枚举这些计划：
  - **第一次遍历（Pass 1）**：为每个单独的关系找到最佳的1-关系计划。
  - **第i次遍历（Pass i）**：找到将（i-1）关系计划结果作为外部表来与第i个关系进行连接的最佳方法。这里的i是介于2到N之间的数。
- 在考虑关系的每个子集时，只保留两种计划：
  - 总体上成本最低的计划。
  - 每个有趣的元组顺序（interesting order）的最低成本计划。

**有趣的顺序**指的是元组的顺序对于下游操作有特殊用途，比如它可能减少排序的需要，或者提高连接操作的效率。

# 题目-归档

#### SQL 

##### 2024 hw

