# 计算机视觉笔记

# Lec 1 Intro

[paperwithcode][1] 

**PyTorch**：由于其易于理解的编程风格和动态计算图，PyTorch 在研究领域特别受欢迎。它的直观性使得开发新算法和实验新想法变得简单。

**TensorFlow**：相比之下，TensorFlow 在工业界更为流行，尤其是在需要大规模部署的场景中。TensorFlow 提供了一个全面的生态系统，包括用于生产部署的工具和资源。

CVPR,ICCV(全球),ECCV 计算机视觉顶会

1. **初始化太小**：如果权重初始化得太小，那么网络中的激活值（activations）会接近于零，同样的，梯度（gradients）也会接近于零，这会导致网络无法学习。
2. **初始化太大**：如果权重初始化得太大，那么在使用tanh这类激活函数时，网络中的激活值会饱和，这同样会导致梯度接近于零，进而网络无法学习。
3. **初始化正好**：理想的情况是，权重初始化应该使得激活值在所有层中都有一个好的分布，这样可以确保梯度也有一个好的分布，从而使学习过程顺利进行。

# Lec 2 camera

#### 小孔成像模型(Thepinholeprojectionmodel)

<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240305155210808.png" alt="image-20240305155210808" style="zoom:50%;" />



并不是所有相交线都是平行的

focal length ( *f* ) 焦距

the distance of the object from the optical center  (*D*) 物镜距离

the distance at which the object will be in focus (*D*′) 像镜距离

##### 景深和光圈的关系

大光圈让更多光线进入，景深浅，背景模糊；小光圈让较少光线进入，景深深，背景更清晰。但是，小光圈降低了曝光量，所以需要通过增加曝光时间或提高ISO来补充光线。

##### FOV（Field of View，视场角）

是指相机镜头能够覆盖的视野范围。它通常以角度来表示，描述了从相机的视点出发，能够看到的空间区域的广度。FOV越大，相机能够捕捉到的场景就越宽广，但同时可能会导致图像中的物体看起来更小或更远。相反，FOV较小则意味着相机的视野范围更窄，可以更加集中地观察到特定的细节，但会捕捉到较少的背景信息。<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240307112459457.png" alt="image-20240307112459457" style="zoom:50%;" />

FOV depends on focal length and size of the camera retina
$$\varphi=\tan ^{-1}\left(\frac{d}{2 f}\right)$$

Larger focal length $=$​ smaller FOV

这个方程是用来计算相机视场角(Field of View, FOV)的，它展示了视场角与焦距（focal length，记为f*f*）和相机感光元件（通常称为相机的“视网膜”或sensor，记为d*d*）大小之间的关系。

- 如果焦距增大（f*f*增大），视场角变小，因为相机的视角更加“放大”或“拉近”了，这通常用于远距离拍摄，比如野生动物摄影或体育摄影中使用的长焦镜头。
- 如果焦距减小（f*f*减小），视场角变大，因为相机的视角更加“缩小”或“拉远”，可以看到更广阔的场景，这通常用于风景摄影或室内摄影中使用的广角镜头。

公式中：

- *φ* 是视场角(Field of View)的一半。
- d 是相机感光元件的对角线尺寸。
- *f* 是镜头的焦距。



No,film上的任何一个点会有各种颜色各种地方的叠加

Projective Geometry

What is lost? • Length • Angles

What is preserved? • Straight lines are still straight

#### 消失点和消失线

##### 消失点的定义：

- 所有平行线都汇聚于一个消失点
  - 空间中的每个方向都与其自己的消失点相关联
  - 例外：平行于图像平面的方向

消失点：在三维世界中的平行线在投影中相交于一点

消失线: 在三维世界中的平行平面相交于一条线

“一个图案在与图像平面平行的平面上的投影会发生什么情况？
- 那个平面上的所有点都位于一个固定的深度z
- 图案会按照f/z的比例进行缩放，但角度和长度/面积的比例是保持不变的。”

非齐次坐标系通常用来表示三维空间中的点。在这个坐标系中，一个点P可以表示为原点 $\mathrm{O}$ 和基向量i、j、k 的线性组合, 其中 $X 、 Y 、 Z$​ 是点P的坐标值。

<img src= "notes_images/vanishing_point.jpg">

当我们需要在不同的坐标系中表示同一个点 $P$ 时, 我们可以使用一个旋转矩阵R和一个平移向量 $t$来进行坐标转换。这里, $\overrightarrow{O P}$ 是点 $\mathrm{P}$ 在坐标系 $\mathrm{F}$ 中的位置向量, ${ }^A P$ 是点 $\mathrm{P}$ 在坐标系 $\mathrm{A}$ 中的位置, ${ }^B P$ 是点 $\mathrm{P}$ 在坐标系 $\mathrm{B}$​ 中的位置。

#### 视角失真（Perspective distortion)

被投影的柱子宽度是相等，外部的柱子更宽。这并不是一种光学错觉，也不是由于镜头缺陷造成的。。当我们观看一排并列的物体，比如柱子时，最靠近我们的物体看起来会比远处的物体宽。这是因为我们的视线相对于较近的物体更为散开，这导致它们在我们视网膜上占据更大的空间，尽管它们实际上可能是等宽的。

<img src = "notes_images/Perspectivedistortion.jpg" style="zoom:50%;" >

<img src = "notes_images/sphere.jpg " style="zoom:50%;" >

<img src = "notes_images/project_sphere.jpg" style="zoom:50%;" >

#### 投影放缩

$$(x, y, z) \rightarrow\left(f \frac{x}{z}, f \frac{y}{z}\right)$$



The same point $P$ in different coordinate systems
$(A)$ and $(B)$ :
$${ }^A \boldsymbol{P}=\mathcal{R}^B \boldsymbol{P}+\boldsymbol{t},$$

Here $\boldsymbol{R}$ is a rotation matrix, $\boldsymbol{t}$​ is a translation vector.

Homogenous Coordinates
Add one more coordinate:
$$\begin{array}{cc}
(x, y) \Rightarrow\left[\begin{array}{c}
x \\
y \\
1
\end{array}\right] & (x, y, z) \Rightarrow\left[\begin{array}{c}
x \\
y \\
z \\
1
\end{array}\right] \\
\text { homogeneous image } & \text { homogeneous scene } \\
\text { coordinates } & \text { coordinates }
\end{array}$$

By introducing homogenous coordinates, we have
$$ { }^A \boldsymbol{P}=\mathcal{T}^B \boldsymbol{P}, \quad \text { where } \quad \mathcal{T}=\left(\begin{array}{cc}
\mathcal{R} & \boldsymbol{t} \\
\mathbf{0}^T & 1
\end{array}\right),
$$
  $$#### 齐次坐标的投影

$p=\frac{1}{Z} \mathcal{M} \boldsymbol{P}$，M包含了想记得内参和相机的外参(和world coordinate 相关)

#### 相机内参（Intrinsic Parameters）

x和y是已像素点作为单位

> 参数与摄像机的物理特性有关，包括像素的大小、成像传感器（如CCD）的中心，以及由于制造误差导致的成像传感器平面的非正交性。

- 图像点 p的坐标 (x,y) 用像素单位表示，而不是米。

- 像素可能是矩形的而非正方形的（即可能有偏斜）。

- 成像传感器的中心通常不与图像的中心 c0 重合。

- 由于制造误差，图像轴之间的角度可能不是 90 度。

- 这里的公式:
  $$%$$
  \begin{aligned}
  & x=k\_f \frac{X}{Z}=k \alpha, \quad \alpha=k\_f \text { and } \beta=l\_f \\
  & y=l\_f \frac{Y}{Z}=l \beta
  \end{aligned}
  $$%$$

  其中 $k$ 和 $l$ 是像素的宽度和高度, $f$ 是焦距， $\alpha$ 和 $\beta$ 是与像素尺寸和焦距相关的缩放因子。

  当传感器的中心不与图像中心对齐时, 坐标 $(x, y)$ 可以用下面的式子修正:
  $$%$$
  \begin{aligned}
  & x=\alpha \hat{x}+x\_0 \\
  & y=\beta \hat{y}+y\_0
  \end{aligned}
  $$%$$

  这里, $x_0$ 和 $y_0$ 表示图像中心的像素坐标。

  \>   1. **视角偏斜**：当传感器的中心偏离图像中心时，图像会出现视角偏斜，即图像的一部分看起来会比另一部分大。这会导致在图像边缘的物体比中心的物体显得更大或更小，从而产生非对称的视觉效果。
  \> 2. **几何畸变**：不对齐可能导致图像的几何形状失真。例如，一个完美的方格可能会在图像上呈现为梯形或其他不规则形状。
  \> 3. **对焦问题**：如果传感器和镜头中心不对齐，可能会导致图像的某些区域无法正确对焦。
  \> 4. **边缘模糊**：由于透视原因，如果传感器不是完全水平，图像的边缘可能会比中心更模糊。

  最后的公式考虑了由于像素轴之间的角度不是正好 90 度的制造误差, 导致像素的轴有一定的倾斜:


$$
\begin{aligned}
  & x=\alpha \hat{x}-\alpha \cot \theta \hat{y}+x_0 \\
  & y=\frac{\beta}{\sin \theta} \hat{y}+y_0
  \end{aligned}
$$



$$
$$%$$$$
  
  
  
  其中, $\theta$ 是两个像素轴之间的角度。当 $\theta$ 等于 90 度时, 上述公式退化为正常的尺度变换和平移变换, 因为 $\cot 90^{\circ}=0$ 和 $\sin 90^{\circ}=1$ 。

1. **Less light gets through** - 如果光圈很小，通过的光量就会减少，这意味着感光元件接收到的光线更少，可能会导致照片曝光不足。
2. **Diffraction effects** - 当光圈非常小的时候，光的衍射效应变得更加明显，这会导致图像失焦，从而降低图像的清晰度。衍射是波（此处指光波）遇到障碍物时发生弯曲的现象，当光穿过一个小光圈时，会产生衍射，影响成像质量。

1. **初始化**：设定迭代次数 N，选择点的数量 s（对于线性拟合 s=2），内点距离阈值 t，以及接受模型所需的最小内点数 d。
2. **随机抽样**：从数据集中随机选择 s 个点（对于线性拟合即随机选择 2 个点），这些点被用来拟合初步的模型（在本例中为直线）。
3. **模型拟合**：通过这 s 个点计算直线的参数（例如，利用最小二乘法）。
4. **内点计数**：计算数据集中每个点到上一步拟合的直线的距离，并确定哪些点的距离小于阈值 t。所有距离小于 t 的点被视为内点。
5. **评估模型**：如果内点的数量达到或超过了 d，那么认为这个模型是有效的，并且使用所有内点重新拟合直线，以获得更准确的模型参数。
6. **迭代**：重复步骤 2 到 5，总共进行 N 次迭代。每次迭代可能会找到不同的内点集合。
7. **选择最佳模型**：在所有迭代中，选择内点数量最多的模型作为最终的拟合结果。

**最小二乘法**提供了一种系统化的方法来估算一组数据点最佳拟合直线的参数，这在统计学和数据分析中是非常有用的。

##### 拜耳滤镜阵列（Bayer Filter Array）

> 因为人眼对绿色的敏感度最高，所以在拜耳阵列中绿色滤镜的数量是红色和蓝色的两倍。这种排列模式也被称为RGBG或GRBG模式。

因为每个传感器像素仅能感知一种颜色，所以需要通过一种叫做去马赛克或者色彩插值的算法来估算出每个像素位置上的完整RGB颜色。这个过程利用了相邻像素的颜色信息来推断缺失的颜色。





$\hat{x}=\frac{X}{Z}$ 和 $\hat{y}=\frac{Y}{Z}$
这里 $X, Y, Z$ 是三维空间中的点 $P$ 的坐标。而 $\hat{x}$ 和 $\hat{y}$ 是点 $P$ 投影到以相机为中心, 与相机光轴 (Z轴) 垂直的平面上的坐标。这个平面称为**归一化图像平面,** 因为它在摄像机的焦距（通常假定为单位距离）上定义。归一化坐标是指在这个假想的平面上, 垂直于光轴并穿过光心（相机的中心点) 的坐标系中的坐标。
$$\hat{p}=\frac{1}{Z}\left(\begin{array}{ll}\mathrm{Id} & 0\end{array}\right) P$$
在这里, $\hat{p}$ 是归一化图像平面上的点的向量表示, 而 $P$ 是三维空间中的点的向量表示。矩阵
$(\mathrm{Id} 0)$ 用于提取 $P$ 中的 $X$ 和 $Y$ 坐标, 并忽略 $Z$ 坐标, 因为在归一化图像平面上, 我们只关心 $X$ 和 $Y$ 的比例。

- $\alpha$ 是 $x$ 轴的缩放系数。 这是将图像的x坐标（即水平坐标）从世界单位（如米）转换为像素单位的系数。它取决于相机的焦距和传感器上每个像素的实际宽度。
- $\beta$ 是 $\mathrm{y}$ 轴的缩放系数。 这是将图像的y坐标（即垂直坐标）从世界单位转换为像素单位的系数。它取决于相机的焦距和传感器上每个像素的实际高度。
- $\theta$ 是 $x$ 轴和 $y$ 轴之间的倾斜角度。
- $x_0$ 和 $y_0$​ 是成像中心在图像坐标系中的位置。

Putting all equations together, we get
$\boldsymbol{p}=\mathcal{K} \hat{\boldsymbol{p}}$, where $\boldsymbol{p}=\left(\begin{array}{l}x \\ y \\ 1\end{array}\right)$ and $\mathcal{K} \stackrel{\text { def }}{=}\left(\begin{array}{ccc}\alpha & -\alpha \cot \theta & x_0 \\ 0 & \frac{\beta}{\sin \theta} & y_0 \\ 0 & 0 & 1\end{array}\right)$.



Here $\mathcal{K}$​​ is called (Internal) calibration matrix of the camera.
$$p=\frac{1}{Z} \mathcal{K}\left(\begin{array}{ll}
\operatorname{Id} & 0
\end{array}\right) \boldsymbol{P}=\frac{1}{Z} \mathcal{M} \boldsymbol{P}, \quad \text { where } \quad \mathcal{M} \stackrel{\text { def }}{=}\left(\begin{array}{ll}
\mathcal{K} & 0
\end{array}\right)$$

1. **旋转矩阵 R**: 它是一个 3x3 矩阵，表示世界坐标系相对于摄像机坐标系的旋转。它定义了一个坐标系到另一个坐标系的方向变换。

2. **平移向量 t**: 它是一个三维向量，表示摄像机原点在世界坐标系中的位置。

   \#\# 相机的外参(Extrinsic Parameters)

   从世界坐标系（通常表示为 W）到摄像机坐标系（通常表示为 C）

   ${ }^C P$ 表示的是摄像机坐标系中的点。
   ${ }^W P$ 表示的是世界坐标系中的点。
   $R$ 是一个 $3 \times 3$​ 的旋转矩阵, 它描述了从世界坐标系到摄像机坐标系所需的旋转。

   在三维空间中, 旋转矩阵通常是 $3 \times 3$ 的, 可以表示为绕三个主轴之一的旋转, 也就是绕 $x 、 y$ 或 $z$ 轴。这些旋转通常用欧拉角 (Euler angles) 来描述, 即绕 $x$ 轴的旋转角 $\alpha$ 、绕 $y$ 轴的旋转角 $\beta$ 和绕 $z$ 轴的旋转角 $\gamma$ 。

   例如, 一个绕 $z$ 轴的旋转角 $\gamma$ 的旋转矩阵 $R_z(\gamma)$ 是这样的:
$$
$$
   R_z(\gamma)=\left[\begin{array}{ccc}
   \cos (\gamma) & -\sin (\gamma) & 0 \\
   \sin (\gamma) & \cos (\gamma) & 0 \\
   0 & 0 & 1
   \end{array}\right]
$$



类似地, 我们有绕 $x$ 轴的 $R_x(\alpha)$ 和绕 $y$ 轴的 $R_y(\beta)$ 。

   $t$ 是一个 3 维的平移向量, 描述了世界坐标系原点到摄像机坐标系原点的距离和方向。
   $p$ 表示图像平面上的点, 而 $Z$ 是 ${ }^C P$ 在摄像机坐标系中的深度（即 ${ }^C P$ 的第三个坐标）。

图片中的公式 $\boldsymbol{C P}=\left(\begin{array}{cc}\boldsymbol{R} & \boldsymbol{t} \\ \mathbf{0}^T & 1\end{array}\right) \boldsymbol{W} \boldsymbol{P}$ 用来将世界坐标系中的点 $\boldsymbol{W} \boldsymbol{P}$ 转换到摄像机坐标系中的点 $\boldsymbol{C P}$ 。这是通过对世界坐标系中的点应用旋转和平移来实现的。
$$T=\left[\begin{array}{cc}
R & t \\
0^T & 1
\end{array}\right]$$

其中, $R$ 是 $3 \times 3$ 的旋转矩阵, $t$ 是 $3 \times 1$ 的平移向量, $0^T$ 是 $1 \times 3$ 的零向量, 1 是一个标量值。这个矩阵 $T$ 可以将三维点从一个坐标系（例如世界坐标系）变换到另一个坐标系（例如摄像机坐标系)。

最后, 通过内参矩阵 $\kappa$ 和外参 $(\boldsymbol{R} \quad \boldsymbol{t})$, 可以得到最终的投影点 $p$, 即 $p=\frac{1}{Z} \boldsymbol{M}$ ，其中 $\boldsymbol{M}$ 是内参矩阵和外参矩阵的结合。这个公式用于将三维空间中的点 $P$ 转换到二维图像平面上的点 $p 。 Z$ 是点 $P$ 在摄像机坐标系中的深度值。

##### Q:为什么光圈越小越清晰？

<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240307104953559.png" alt="image-20240307104953559" style="zoom:50%;" />

(1) 只有一束光 最清晰 ，但是特别暗

(2) 太小会发生衍射效应



<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240307105632571.png" alt="image-20240307105632571" style="zoom:50%;" />

蓝色点超出景深范围内（单反就是会这样，傻瓜相机就不会）

##### 凸透镜成像规律

![img][image-1]

制景深（depth of field，简称DOF）的原理。景深是指在照片中看起来清晰的那部分区域的范围。这个范围可以通过调整相机的光圈大小来控制。光圈是镜头中的一个可调节的开口，它能影响透过镜头的光线量。

浅景深：<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240307111327304.png" alt="image-20240307111327304" style="zoom:50%;" />

大景深：<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240307111349627.png" alt="image-20240307111349627" style="zoom:50%;" />



<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240307111834636.png" alt="image-20240307111834636" style="zoom:50%;" />

- **较大的光圈（上图）**：光圈大时，透过的光线量增加，导致景深较浅。这意味着只有离相机较近的物体会清晰，而远处的物体会变得模糊。这通常用于肖像摄影，以突出主题，背景则故意模糊处理。
- **较小的光圈（下图）**：光圈小时，透过的光线量减少，导致景深较深。这意味着从相机较近到较远的物体都会相对清晰。这通常用于风景摄影，因为它允许整个场景都保持清

- “A smaller aperture increases the range in which the object is approximately in focus”（较小的光圈增加了物体大致清晰的范围）。
- “But small aperture reduces amount of light — need to increase exposure”（但小光圈减少了光线量 — 需要增加曝光时间）

<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240307111930063.png" alt="image-20240307111930063" style="zoom:50%;" />

称为光晕（Vignetting，中文有时翻译为晕影）。光晕是由于镜头设计的缺陷或使用上的限制，导致相机拍摄的图片边缘暗于中心部分。

1. **桶形畸变（Barrel Distortion）**：在这种畸变中，图像的中心被压缩，而边缘被拉伸，导致图像看起来像是被包裹在一个桶表面上。这常见于广角镜头，如鱼眼镜头。
2. **枕形畸变（Pincushion Distortion）**：这与桶形畸变相反，图像的边缘向内弯曲，中心部分被拉伸，使得图像看起来像是被嵌入在一个枕头中。这种畸变通常发生在长焦镜头中。

比如红色，感受红光的强度 0\~255 

点积 $S \cdot N$ 的结果是一个标量，表示入射光向量在表面法线方向上的分量，这也等同于入射光和表面法线之间的夹角 $\theta$ 的余弦。当入射光与法线方向一致（垂直入射）时, $\cos \theta$ 的值为 1 , 此时反射光强度最大。当光以越来越倾斜的角度入射时, $\cos \theta$ 的值减小, 反射光强度也随之减小。

图中的插图展示了入射光线以不同的角度照射到两个不同方向的平面上（分别标记为 $A$ 和 $B$ ) 。由于 $B$ 点的表面与光线的入射角更大, 因此根据兰伯特余弦定律, 该点的反射光强度I会小 $A$ 点的反射光强度。

在图中所示的公式 $E=\left[\frac{\pi}{4}\left(\frac{d}{f}\right)^2 \cos ^4 \alpha\right] L$ 中:
- $E$ 表示图像的辐照度（irradiance）, 也就是单位面积上的光通量, 通常用瓦特每平方米表示。
- $d$ 是光圈直径。
- $f$ 是焦距, 即镜头的光心到成像平面的距离。
- $\alpha$ 是光线与光学轴之间的角度, 也就是视场角。
- $L$ 是场景的辐射度 (radiance), 表示特定方向上单位面积上的光通量, 这是一个描述光源亮度的量。

**射度 (Radiance - L)**：

- 辐射度是单位面积（平方米）单位立体角（steradian）的能量流量（瓦特），描述的是从一个点P向另一个点P'发射的光的亮度或强度。

- 辐射度衡量了一束光在特定方向上的亮度，这不仅包括了光的量，还包括了光的方向性。因此，它能够描述光源的定向特性。

- 辐射度考虑了光在空间中的传播方式，因此它通常用于描述从表面或体积中发出或通过的光量

- **辐照度 (Irradiance - E)**：

  - 辐照度是单位面积（平方米）接收到的能量流量（瓦特），描述的是落在点P'上来自透镜的光的量。

  - 辐照度是一个表面在给定时间内接收的光能量的度量。与辐射度不同，它不考虑光的方向性，而是纯粹度量能量本身。

  - 辐照度常用于测量和分析如何以及有多少光照射到了一个表面上，比如太阳对地面的照射。

	


### 推拉变焦

当摄像机向后移动（即远离主体）时，你会增加镜头的焦距（zoom in），而当摄像机向前移动（朝向主体）时，则会减小焦距（zoom out）。

### 球面像差

\#\#\#\# 

- 已知量：源向量 $S_j$ 和像素值 $I_j(x, y)$ 。
- 未知量: 表面法线 $N(x, y)$ 和反照率 (albedo） $\rho(x, y)$ 。
- **反照率（albedo）** 是物体表面反射的光与入射光总量的比率，它是没有单位的，并且对于朗伯表面，是一个常数。
- 朗伯定律（Lambert's law）告诉我们, 朗伯表面的亮度不依赖于观察者的角度。对于给定的光源和表面法线，朗伯表面的像素值 $I_j(x, y)$ 可以通过下面的方程计算:
  $$%$$
  $$%$$
  I\_j(x, y)=k \rho(x, y)\left(N(x, y) \cdot S\_j\right)
  $$%$$
  
  
  
  其中：
  - $I_j(x, y)$ 是图像中点 $(x, y)$ 在第 $j$ 个光源下的像素亮度。
  - $k$ 是相机响应的缩放因子。
  - $\rho(x, y)$ 是点 $(x, y)$ 的反照率。
  - $N(x, y)$ 是点 $(x, y)$ 的表面法线。
  - $S_j$ 是第 $j$ 个光源的方向。
  方程的右侧表示光照模型, 其中 $\left(N(x, y) \cdot S_j\right)$ 是表面法线与光源向量之间的点积, 代表了光源方向和表面法线方向之间的角度关系。点积越大, 意味着表面与光源方向越对齐, 相应的像素就越亮。

##### 漫反射

它是指光线入射到粗糙或不光滑的表面上时，如粉笔或乳胶漆等哑光表面，光线被均匀地向各个方向散射的现象。这种表面由许多微小的面（微小平面）组成，这些面向各个方向随机地散射光线。

# Lec3 light

图中的公式 $I(x)=\rho(x)(S \cdot N(x))$ 是光照强度的计算模型, 它是根据兰伯特余弦定律得出的。根据这个定律, 一个表面上某点的反射光强度与入射光的角度成正比。这里的变量定义如下:

- $\rho$ （读作rho）代表表面的反照率（albedo）, 即表面反射光线的能力, 它是没有单位的比例因子, 取值范围通常在 0 到 1 之间。不同材料的反照率不同,例如雪的反照率非常高, 而煤的反照率非常低。
- $S$ 是光源方向向量，表示光源的位置和方向。
- $N$ 是表面法线（surface normal），表示垂直于表面点的方向。
- $I$ 是该点的反射光强度（reflected intensity）, 表示该点反射的光线强度。
- $\cdot$代表点积 (dot product), 它是一个数学运算, 用来衡量两个向量的相似度。在这个公式中, 点积用来计算入射光向量和表面法线之间的夹角的余弦值。

1. **吸收 (Absorption)**：当光线遇到材料时，部分光能会被材料吸收，转化为其他形式的能量，例如热能。吸收会使通过材料的光强减弱，通常与材料的颜色相关联。例如，一个红色的苹果吸收了除红光以外的大部分光谱。
2. **扩散 (Diffusion)**：扩散是指光线在经过介质（如大气或磨砂玻璃）时方向上的散射。这会导致光线从多个方向传播，产生柔和的阴影和边缘。这是照相机朦胧效果或天空光的柔和效果的原因。
3. **反射 (Reflection)**：当光线从一个介质（如空气）进入另一个不同的介质（如镜子）时，部分光线会被反射回原来的介质。反射分为两种类型：镜面反射（光线以相同的角度反射）和漫反射（光线以多个角度反射）。
4. **透明度 (Transparency)**：透明度是指材料允许光线通过而不被吸收或散射的程度。完全透明的物体，如清水或玻璃，允许光线完全通过，使物体或物体的另一侧清晰可见。
5. **折射 (Refraction)**：折射是指光线在穿过不同折射率介质的界面时，其传播方向发生改变的现象。例如，当光线从空气进入水中时，会朝着垂直于界面的方向偏折，这就是我们在水中看到物体位置看起来“弯曲”的原因。
6. **荧光 (Fluorescence)**：荧光是一种特殊的发光过程，当物质吸收光能（通常是紫外线）后，会以较长的波长（例如可见光）重新发射光能。这就是荧光物质在黑光下发光的原因。
7. **次表面散射 (Subsurface scattering)**：次表面散射是指光线进入物体表面后，在物体内部进行多次散射再重新射出的过程。这种效果常见于如皮肤、蜡、果肉等半透明物质，使其看起来有一种特殊的深度和真实感。
8. **磷光 (Phosphorescence)**：磷光与荧光相似，也是物质吸收光能后再发射光能的过程，但磷光具有延迟特性，即物质在停止接受激发光后，仍能持续发光一段时间，如夜光表或夜光贴纸。
9. **互反射 (Interreflection)**：互反射是指光线在多个表面之间多次反射的现象。这在封闭空间内或物体间距较近时尤其明显，如房间内的墙壁互相反射光线，增加了场景的整体亮度和色彩的复杂度。



### 光度立体测量（Photometric Stereo）

- **Lambertian object**：这指的是一个理想的漫反射表面。

  >  Lambertian表面的特点是它们各向同性地散射入射光——也就是说，光线无论从哪个方向照射到这种表面上，都会以相同的亮度反射。

  满足公式:

  $\begin{aligned} I_j(x, y) & =k \rho(x, y)\left(\mathbf{N}(x, y) \cdot \mathbf{S}_j\right) \\ & =(\rho(x, y) \mathbf{N}(x, y)) \cdot\left(k \mathbf{S}_j\right) \\ & =\mathbf{g}(x, y) \cdot \mathbf{V}_j\end{aligned}$

- **Local shading model**：这是指局部的阴影模型，意味着表面上每一点的亮度仅由对该点可见的光源决定。这忽略了如全局照明、间接光或反射光等复杂因素。

- **Known light source directions**：知道用于照射对象的每一个光源的方向。

- **Set of pictures**：这些是在完全相同的相机和对象配置下，但使用来自不同方向的光源拍摄的一系列图片。

- **Goal**：最终的目标是重建对象的形状（即表面的法线）和反照率（albedo）。

  

  > 这通常通过解析每个像素在不同光照条件下的亮度变化来实现，从而估算出表面法线和反照率。这样，即使物体本身是固定的，通过变换光源方向和分析得到的影像，也可以获取物体表面的详细几何信息。

<img src = "notes_images/光线与反射角度.jpg" style="zoom:50%;" >

surface norm 与

法向量 $\mathbf{N}(x, y)$ 表示了曲面在点 $(x, y)$ 处的垂直方向。对于上述曲面, 法向量的计算公式是:
$$
\mathbf{N}(x, y)=\frac{1}{\sqrt{f_x^2+f_y^2+1}}\left(\begin{array}{c}
f_x \\
f_y \\
1
\end{array}\right)
$$


接下来, 通过观察给定的法向量 $\mathbf{N}(x, y)$, 我们可以得到关于 $f_x(x, y)$ 和 $f_y(x, y)$ 的信息。在这里, 我们用 $g_1(x, y), g_2(x, y)$ 和 $g_3(x, y)$ 来表示法向量的三个分量。根据法向量的定义, 我们可以写出:
$$
\begin{aligned}
& f_x(x, y)=g_1(x, y) / g_3(x, y) \\
& f_y(x, y)=g_2(x, y) / g_3(x, y)
\end{aligned}
$$

surface norm 已知,S已知，应该不做要求，是CVPR的一篇论文：P. Nillius and J.-O. Eklundh, “Automatic estimation of the projected light source direction,” CVPR 2001

通过光源来判断是不是假照片:M. K. Johnson and H. Farid, Exposing Digital Forgeries by Detecting Inconsistencies in Lighting, ACM Multimedia and Security Workshop, 2005.



# Lec4 color

#### 什么是颜色？

• 颜色是环境中的物理光与我们的视觉系统相互作用的结果

 • 颜色是我们观看物体和灯光时视觉体验的心理属性， 不是这些物体或光的物理属性

这张图显示的是电磁谱，包括从高频的伽马射线到低频的长波无线电波。上面的图展示了不同类型的电磁波，包括伽马射线、X射线、紫外线、可见光、红外线、微波、调频（FM）和振幅调制（AM）无线电波，以及长波无线电波。电磁波的频率从左边的高频（ν）到右边的低频，波长从右边的长波长（λ）到左边的短波长。

下面的图展示的是人类的视觉相对灵敏度函数，这是一个标准的曲线，展示了人眼对不同波长可见光的感光度。最高点大约在555纳米处，这是黄绿色的光，人眼对这个波长的光最为敏感。曲线两边逐渐下降，表示人眼对紫色端（约400纳米）和红色端（约700纳米）的光相对不太敏感。这段可见光谱是电磁谱中人眼可以感知的部分，也是我们所能看到的“颜色”的来源。



RGB和HSV

<img src = "notes_images/HSV.jpg" style="zoom:50%;" >



> 既然“**三原色的原理不是出于物理原因，而是由于 生理原因造成的**”，那么通常所说的“**用三种原色 的光以不同的比例加和到一起，形成各种颜色的 光**”显然就不大合适。$\textcolor{red}{使用三原色并不足以重现所 有的色彩}$，准确地说法应该是“**将三原色光以不同 的比例复合后，对人的眼睛可以形成与各种频率 的可见光等效的色觉**。”只有那些在三原色的色度 所定义的颜色三角内的颜色，才可以利用三原色 的光以非负量相加混合得到。

1. - 提取并存储每张图片的颜色直方图。颜色直方图是图像中颜色分布的图形表示。
2. **给定新的查询图像**：
   - 提取这张查询图像的颜色直方图。
3. **对于数据库中的每张图像**：
   - 计算查询图像的颜色直方图和数据库中图像的颜色直方图之间的交集。这里的“交集”指的是两个直方图中对应颜色值的最小值。
4. **对交集值进行排序**：
   - 交集值越大，表示查询图像与数据库中图像的颜色分布越相似。
5. **根据交集值排序的顺序对数据库中的图像进行排名**：
   - 交集值最高的图像与查询图像最为相似，因此排在最前面。





#### 分光辐射计

#### 相机标定（Camera Calibration）

**选择标定物**: 在图像中, 我们可以看到一个带有明显格点的标定板, 这些点的三维坐标 $X_i$ 是已知的。
**捕捉图像：**通过摄像头捕捉包含标定板的图像。在图像中, 每个点 $X_i$ 的投影（即图像中的位置) 被标记为 $x_i$ 。
**确定摄影机参数：**使用上述已知的三维点和它们在图像中的二维投影, 我们可以估计摄影机参数。这些参数通常包括内参（如焦距、主点坐标、镜头畸变系数）和外参（如摄影机在全球坐标系中的位置和旋转) 。
**建立数学模型:** $P$ 在示意图中代表摄影机投影矩阵, 它是一个 $3 \times 4$ 矩阵, 用于将三维点转换为二维图像点。通过解决一系列线性方程组, 我们可以求解出这个矩阵。这些方程由以下公式建立: $x_i=P X_i$
其中 $x_i$ 是三维点在图像上的投影（扩展为齐次坐标）， $X_i$​ 是三维空间中的点（同样表示为齐次坐标) 。
优化参数：通常会通过最小化重投影误差（即，算法预测的图像点位置与实际观测到的位置之间的差异) 来优化摄影机参数。

> 在这个步骤中, 我们有一个三维场景中的点 $X_w^{(i)}, Y_w^{(i)}, Z_w^{(i)}$ (其中 $w$ 代表世界坐标系) , 我们知道它在图像上的对应二维点 $u^{(i)}, v^{(i)}$ 。我们想要计算能将三维世界坐标转换到二维图像坐标的摄像机的投影矩阵 $P$ 。
> 
> 矩阵 $P$ 包含了我们想要求解的摄像机参数, 它是一个 $3 \times 4$ 的矩阵, 由 12 个未知数 $p_{11}, p_{12}, \ldots, p_{34}$ 组成。这些参数包含了摄像机的内部特性（如焦距、成像中心等）和外部特性 （如位置和方向）。

$$\left[\begin{array}{c}u^{(i)} \\ v^{(i)} \\ 1\end{array}\right]=\left[\begin{array}{llll}p_{11} & p_{12} & p_{13} & p_{14} \\ p_{21} & p_{22} & p_{23} & p_{24} \\ p_{31} & p_{32} & p_{33} & p_{34}\end{array}\right]\left[\begin{array}{c}X_w^{(i)} \\ Y_w^{(i)} \\ Z_w^{(i)} \\ 1\end{array}\right]$$

$$\begin{aligned} & u^{(i)}=\frac{p_{11} X_w^{(i)}+p_{12} Y_w^{(i)}+p_{13} Z_w^{(i)}+p_{14}}{p_{31} X_w^{(i)}+p_{32} Y_w^{(i)}+p_{33} Z_w^{(i)}+p_{34}} \\ & v^{(i)}=\frac{p_{21} X_w^{(i)}+p_{22} Y_w^{(i)}+p_{23} Z_w^{(i)}+p_{24}}{p_{31} X_w^{(i)}+p_{32} Y_w^{(i)}+p_{33} Z_w^{(i)}+p_{34}}\end{aligned}$$

在计算机图形学和计算机视觉中, 齐次坐标用于方便地表示三维空间中的点和变换。齐次坐标有一个额外的维度（通常表示为 $w$ ），它允许我们用线性代数（矩阵乘法）来表示仿射变换，例如平移，这在普通笛卡尔坐标系中是不可能的。

幻灯片上的等式表明, 齐次坐标 $[\hat{u}, \hat{v}, \hat{w}]^T$ 可以乘以一个非零常数 $k$, 而不改变对应的笛卡尔坐标的点 $\left[\frac{\hat{u}}{\hat{w}}, \frac{\hat{v}}{\hat{\hat{w}}}\right]$ 。换句话说, 尽管 $\hat{u}, \hat{v}, \hat{w}$ 的值可以根据 $k$ 的不同而变化, 但它们代表的二维点的位置不会变。

##### k的意义：

在齐次坐标系统中，一个点的位置可以由多个不同的坐标表示。这些坐标的不同之处在于它们被一个非零常数 k*k* 缩放。这种缩放不会改变点在二维空间中的实际位置。在这个系统中，一个点可以由无限多组坐标来表示，只要这些坐标都是等比例缩放的。常数 k*k* 在这里起的作用是，它展示了即使我们将投影矩阵 P*P* 乘以 k*k*，这个操作所产生的最终2D点仍然是相同的。也就是说，虽然齐次坐标在乘以 k 后看起来数字变大了，但由于它们仍然是等比例的，最终在进行透视除法转换为非齐次坐标时，这个缩放因子 k*k* 会被消除，留下的2D点的实际位置不会改变。

在这个问题中，我们正在寻找一个向量 $\mathbf{p}$，它能够最小化 $|A\mathbf{p}|^2$ 的同时，使得 $|\mathbf{p}|^2=1$。这里 $|\mathbf{p}|$ 表示向量 $\mathbf{p}$ 的二范数，即向量元素平方和的平方根。

幻灯片提供了两种不同的规模设定方式来满足条件 $|\mathbf{p}|^2=1$：

1. 第一种方法是将向量 $\mathbf{p}$ 的第34个元素 $p_{34}$ 设为1。
2. 第二种方法是将向量 $\mathbf{p}$ 的二范数的平方设为1。

为了找到这样的向量 $\mathbf{p}$，我们需要解决一个约束最优化问题。幻灯片给出了这个最优化问题的目标函数，即最小化函数 $\mathbf{p}^T A^T A \mathbf{p}$，同时满足约束条件 $\mathbf{p}^T \mathbf{p}=1$，其中 $\mathbf{p}^T$ 是 $\mathbf{p}$ 的转置。

#### 拉格朗日乘数法
首先讲一下梯度
$$f: \mathbb{R}^n \rightarrow \mathbb{R}数量值函数
(数量场)\\
\vec{f}: \mathbb{R}^n \rightarrow \mathbb{R}^m 向量值函数
(向量场)$$
场:函数选取与坐标系无关
nabla算子/哈密尔顿算子（作用于多元变量）
$$\nabla=\left[\frac{\partial}{\partial x_1}, \frac{\partial}{\partial x_2}, \ldots, \frac{\partial}{\partial x_n}\right]^T$$
$$\nabla f=\left[\begin{array}{c}\frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n}\end{array}\right]$$
梯度总与等值面垂直
$$\begin{gathered}\nabla=\left[\begin{array}{c}\frac{\partial}{\partial x_1} \\ \vdots \\ \frac{\partial}{\partial x_n}\end{array}\right] \vec{f}=\left[\begin{array}{c}f_1 \\ \vdots \\ f_n\end{array}\right] \\ \nabla \cdot \overrightarrow{\boldsymbol{f}}=\frac{\partial f_1}{\partial x_1}+\cdots+\frac{\partial f_n}{\partial x_n}\end{gathered}$$
内积/点乘：把向量场变数量场
向量积：
$$\begin{gathered}\nabla=\left[\begin{array}{c}\frac{\partial}{\partial x} \\ \frac{\partial}{\partial y} \\ \frac{\partial}{\partial z}\end{array}\right] \overrightarrow{\boldsymbol{f}}=\left[\begin{array}{l}f_1 \\ f_2 \\ f_3\end{array}\right] \\ \nabla \times \overrightarrow{\boldsymbol{f}}=\left|\begin{array}{ccc}\overrightarrow{\boldsymbol{i}} & \overrightarrow{\boldsymbol{j}} & \overrightarrow{\boldsymbol{k}} \\ \frac{\partial}{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{\partial z} \\ f_1 & f_2 & f_3\end{array}\right|\end{gathered}$$
#### 最小二乘法解决的优化问题

[1]:	https://paperswithcode.com

[image-1]:	https://pic4.zhimg.com/v2-747a205c0e37c40dc9d17b53b625ee23_b.jpg

# Lec 5 Filter



#### 图像的不同种类

<img src = "notes_images/图片形式.jpg">



#### 卷积核

###### 符号说明

- *f*：表示图像。
- g：表示卷积核（也称为滤波器或kernel）。

#### 卷积核心计算公式

$$
h(x, y)=(f * g)(x, y)=\sum_{i=-a}^a \sum_{j=-b}^b f(x-i, y-j) \cdot g(i, j)
$$

其中, $f(x-i, y-j)$ 是图像在位置 $(x-i, y-j)$ 的像素值, $g(i, j)$ 是卷积核在位置 $(i, j)$的权重值, 而 $a$ 和 $b$ 分别是卷积核 $g$ 的宽度和高度延伸的一半大小 (如果卷积核是奇数大小

1. 卷积核的大小应该是奇数，这样它就会有一个中心点和一个卷积核半径。这意味着，比如一个3x3的卷积核，它的中心就是(2,2)，就是这个网格的正中间。
2. 卷积核中所有元素的总和应该是1。如果总和大于1，则图像会变亮；如果总和小于1，则图像会变暗。这是因为卷积操作涉及到将卷积核的每一个元素与图像上对应的像素值相乘，并把这些乘积相加来得到新的像素值。如果这些乘积的和大于1，则相当于放大了原像素值；如果和小于1，则相当于缩小了原像素值。
3. 卷积后，有些值可能会大于255或小于0。在图像处理中，RGB每个颜色通道的值是在0到255之间的整数，所以任何超出这个范围的值需要被修剪到这个范围内。如果值小于0，就设为0；如果值大于255，就设为255。这样做是为了避免溢出和数据类型不匹配的错误。

### 线性（Linearity）

线性这个术语是指，如果你对两个函数（在这里可以理解为两个图像或两个信号）应用同一个滤波器，那么无论你是先将这两个函数相加后滤波，还是分别滤波后再相加，结果是一样的。这就像数学中的分配律。

表达式 `filter(f1 + f2) = filter(f1) + filter(f2)` 就是在说：

- `f1 + f2`：首先将两个函数（或图像）相加。
- `filter(f1 + f2)`：然后对结果应用滤波器。
- `filter(f1) + filter(f2)`：或者分别对每个函数应用滤波器，然后把结果相加。



### 移位不变性（Shift Invariance）

移位不变性或平移不变性是指，滤波器对于输入信号的处理不会随着信号在空间或时间上的平移而改变。这意味着如果你将一个函数平移一段距离后再应用滤波器，或者是先应用滤波器再平移，结果应该是一样的。

表达式 `filter(shift(f)) = shift(filter(f))` 说明了这一点：

- `shift(f)`：首先将函数（或图像）平移一段距离。
- `filter(shift(f))`：然后对平移后的结果应用滤波器。
- `shift(filter(f))`：或者是先对函数应用滤波器，然后将滤波后的结果平移相同的距离。

两边的结果应该相同，这就是移位不变性。

#### 图像卷积操作时如何处理图像边缘？

1. **裁剪滤波器（Clip Filter / Black）**: 这种方法是指对于超出图像的那部分窗口，直接赋予一个固定的像素值，通常是黑色，即数值为0。
2. **环绕（Wrap Around）**: 这种方法将图像视为环形结构，即当滤波器超出一个边缘时，就从图像的对面边缘继续采样。
3. **复制边缘（Copy Edge）**: 这种方法是将边缘的像素值复制到滤波器窗口之外，即边缘像素被拉伸填充到外部空间。
4. **边缘反射（Reflect Across Edge）**: 这种方法是将图像边缘的像素值镜像反射到滤波器窗口之外，创建一个对称效果。

##### 脉冲滤波

<img src = "notes_images/脉冲滤波.jpg">

##### 平移

<img src = "notes_images/Shift.jpg">

##### Blur

<img src = "notes_images/blur.jpg">

##### Sharpen

<img src ="notes_images/sharpen.jpg">

##### **盒式滤波器的问题：**

这种方法可能会导致图像边缘出现不自然的效果，因为所有像素被平等对待，不管它们离中心有多远。

使用高斯滤波器来实现，高斯滤波器将权重分配给邻域内的像素，权重按照像素距离中心的远近按照高斯函数递减。这样，中心附近的像素对结果的贡献更大，而远离中心的像素贡献较小。这可以创建更自然的模糊效果，尤其是在边缘附近。

##### 高斯核

>  “支撑”是指一个函数非零的区域。如果一个函数在整个数学空间内都可能不为零，即在任意远的地方它的值都有可能大于零，那么这个函数就被称为具有“无限支撑”。无论 $x$ 取多大或多小的值, 这个函数都会给出一个大于零的结果, 因为指数函数 $e^{-\frac{x^2}{2 \sigma^2}}$ 永远不会等于零。但随着 $x$ 值的增大, 这个函数的值会迅速地趋近于零, 尽管如此, 理论上它从不会完全到达零。这意味着无论你观察多么远的地方, 只要 $x$ 的值不是无穷大, 高斯函数的值都是有定义的, 且大于零。这就是所谓的无限支撑。

图片中的数学公式是高斯函数的二维形式:
$$
G_\sigma=\frac{1}{2 \pi \sigma^2} e^{-\frac{\left(x^2+y^2\right)}{2 \sigma^2}}
$$

这里的 $G_\sigma$ 是高斯核, $\sigma$ 是标准差, 决定了平滑的程度。 $x$ 和 $y$ 表示距离核中心的水平和垂直距离。这个函数在中心处有最大值, 并且随着离中心越远而迅速减小。[已经忘掉的高斯分布](https://zhuanlan.zhihu.com/p/481760712)

图片中还展示了两个不同 $\sigma$ 值的高斯核的三维表示, 以及它们在二维图像上的效果:
- 左侧是 $\sigma=2$ 的高斯核, 核的大小是 30×30。可以看到中心峰值很高, 而且很快就降下去了, 这意味着平滑效果较轻, 保留了较多的细节。
- 右侧是 $\sigma=5$ 的高斯核, 同样核的大小是 30×30。这个核的中心峰值较低, 且下降较慢, 这意味着平滑效果更强, 模糊程度更高, 细节保留得较少。

在应用这样的高斯核于图像时, 核中心附近的像素会对最终结果有较大影响, 而离中心远的像素影响较小。选择合适的 $\sigma$ 值对于达到期望的图像处理效果非常关键。标准差 $\sigma$ 越大, 图像越模糊, 边缘效应越小。相反, $\sigma$ 越小, 图像保留的细节就越多。

### Salt and Pepper Noise（椒盐噪声）

椒盐噪声是一种随机出现的黑白像素点噪声，模拟了图像损坏时的效果，就像图像上洒了盐和胡椒粉一样。这种噪声通常是由图像传感器、传输错误、处理过程中的故障等引起的。椒盐噪声的特点是在图像中随机分布的黑色和白色的尖锐亮点。

处理椒盐噪声的常用方法包括中值滤波器（Median Filter），它通过用像素邻域中的中值替换每个像素值来减少噪声

### Impulse Noise（脉冲噪声）

脉冲噪声或称冲击噪声，主要是随机出现的白像素点，有时也会包含黑像素点，但与椒盐噪声相比，它不一定同时包含黑白两种像素。这种噪声可能是由故障像素、传感器噪声或其他外部干扰引起的。

处理脉冲噪声的策略也可以使用中值滤波器，或者采用自适应滤波器，这种滤波器可以根据噪声的特性调整其处理方式。

### Gaussian Noise（高斯噪声）

高斯噪声是指图像中每个像素的强度变化都符合高斯（正态）分布的噪声。这种噪声在自然界中非常常见，因为许多自然和人造过程都产生正态分布的误差。高斯噪声的特点是对整个图像产生一种均匀的“雪花”效果，而不像椒盐噪声或脉冲噪声那样产生孤立的亮点或暗点。

处理高斯噪声的常用方法包括高斯平滑（Gaussian Smoothing）或双边滤波（Bilateral Filtering）。高斯平滑利用高斯函数作为权重，通过平均邻域内像素的值来减少噪声，而双边滤波则在平滑噪声的同时保留边缘信息。



“中值滤波是线性的吗？”答案是不是。中值滤波是非线性的，因为输出值是由输入像素值的顺序决定的，而不是像素值的线性组合。这使得中值滤波在处理非高斯或椒盐噪声时非常有效，因为它可以在不过分模糊图像的情况下，保留边缘和其他细节。

# Lec 6 Edge detection

>  在图像处理中，我们通常处理的是离散数据，而不是连续函数。在这种情况下，我们使用有限差分来近似偏导数。



例如, 对于 $x$ 方向的一阶差分, 一个简单的滤波器可以是:
$$
\left[\begin{array}{ll}
-1 & 1
\end{array}\right]
$$

或者, 为了对相邻像素取平均, 可能会使用:
$$
\left[\begin{array}{lll}
-1 & 0 & 1
\end{array}\right]
$$

这样的核在卷积操作中使用时，会计算图像中每个点与其右侧相邻点的差值。

当这个滤波器（卷积核）在图像上滑动并应用于图像的每一个像素时，它会计算出一个新的图像，其中的每个像素值都是原始图像中相应位置的像素值和其右边像素值的差。这种操作在图像处理中用于边缘检测, 因为边缘通常对应于像素值的快速变化。

![image-20240314115343475](/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240314115343475.png)

白色代表响应数值最高的颜色

设计了很多中卷积kernel 会得到一个特征图

## Recognition 

- 观察角度的变化 **Viewpoint variation**：一句诗可以很好概括，“不识庐山真面目，只缘身在此山中”。
- 尺度变换 **Scale variation**：图片大小比例的变化也会使得数据发生改变。
- 变形 **Deformation**：很多物体的外形不是一成不变的，比如众所周知，猫是液体。 
- 遮挡 **Occlusion**：要被识别的物体可能被遮挡，只露出一部分。
- 光线条件 **Illumination conditions**：环境光线的变化对物体的图片也会有很大的影响。
- 背景干扰 **Background clutter**：如果物体和背景有很相似的颜色和纹路，那么就很难被识别。
- 物种变异 **Intra-class variation**：同一物种可能也有差异很大的形态。

<img src = "notes_images/当前的挑战.jpg">

"Bags of Features"（特征袋）是一种在计算机视觉中常用的方法，特别是在图像分类和检索任务中。这个概念受到自然语言处理中"词袋"模型的启发，其中一篇文档可以表示为它包含的词汇的集合，而不考虑这些词汇在文档中的顺序。

在"特征袋"模型中，图像被描述为局部特征的集合，这些局部特征可以通过不同的方法提取，如SIFT（尺度不变特征变换）、SURF（加速稳健特征）或ORB（Oriented FAST and Rotated BRIEF）等。这些特征被用来代表图像中的关键点，如角点、边缘或斑点等



#### 词频（TF）

词频（TF）指的是某个词语在文档中出现的频率。计算公式是该词在文档中出现的次数除以文档中总词数。这样做的目的是对不同长度的文档进行归一化处理，避免因文档长度的不同而导致的比较偏差。
$$
\mathrm{TF}(t)=\frac{\text { 文档中词条 } t \text { 出现的次数 }}{\text { 文档中的总词条数 }}
$$


#### 逆文档频率（IDF）

逆文档频率（IDF）的目的是减少那些在语料库中频繁出现但对理解文档内容贡献不大的词语的影响（如"的"、"是"等常用词）。它是通过对语料库中包含该词的文档数量取逆并进行对数变换来实现的。具体计算公式为：语料库中文档总数除以包含该词的文档数，然后取对数。
$$
\operatorname{IDF}(t)=\log \left(\frac{\text { 语料库中的文档总数 }}{\text { 含词条 } t \text { 的文档数 }+1}\right)
$$


#### TF-IDF 计算

TF-IDF值是通过将某词的TF值与其IDF值相乘得到的。这个值可以用来评估一个词对于一个文档集合中某一文档的重要性。一个词的TF-IDF值越大，它在该文档中就越重要。这里添加了 1 作为分母, 是为了避免分母为 0 的情况, 这是一种常见的平滑技术。
TF-IDF
将TF和IDF相乘, 得到TF-IDF的公式:
$$
\mathrm{TF}-\operatorname{IDF}(t)=\mathrm{TF}(t) \times \operatorname{IDF}(t)
$$

###### Example(期末要考)

> Consider a document containing 100 words wherein the word *cat* appears 3 times. The term frequency (i.e., tf) for *cat* is ?
>
> Now, assume we have 10 million documents and the word *cat* appears in one thousand of these. Then, the inverse document frequency (i.e., idf) is calculated as ?

$\mathrm{TF}=\frac{3}{100}$ ，$\mathrm{IDF}=\log \left(\frac{10,000,000}{1,000}\right)$

TF-IDF = 0.12

#### Patch

<img src = "notes_images/可以分成大大小小的patch.jpg">

1. **提取局部特征**：这是从图像中识别关键点并描述它们的过程。可以使用SIFT、SURF、ORB等算法来提取这些局部特征。
2. **学习“视觉词汇表”**：一旦从训练集中提取了特征，下一步是构建一个“视觉词汇表”。这通常通过聚类算法（如K-means）完成，聚类算法会将特征归类为"视觉词"。
3. **使用视觉词汇表量化局部特征**：在这一步骤中，将图像中的每个局部特征与视觉词汇表中最接近的词进行匹配，从而为图像创建一个由视觉词频率组成的直方图。
4. **通过“视觉词”的频率表示图像**：最后，图像可以通过它们的“视觉词”直方图表示。这个直方图描述了图像中不同视觉词的分布情况。

<img src = "notes_images/基.jpg">



#### 数据归一化

例子：不同的日历系统

<img src = "notes_images/映射.jpg">

> 1. **测局部特征（Detect patches）**：图像中的局部特征或“补丁”是指图像中具有独特视觉内容的区域，如角点、边缘或特定的纹理区域。这些特征对于识别和理解图像内容非常重要。在这个例子中，这些特征被标记为白色椭圆形。
> 2. **标准化补丁（Normalize patch）**：一旦检测到局部特征，下一步是将这些特征“标准化”，这通常包括调整它们的尺度、方向和亮度，使特征描述更加稳定，不受图像中不相关因素（如照明变化或视角变化）的影响。标准化的补丁在这里显示为一个灰度图像。
> 3. **计算描述符（Compute descriptor）**：最后，计算每个标准化补丁的描述符。描述符是一个数值向量，它量化了补丁的关键视觉特性，如纹理、颜色或梯度方向。描述符使得计算机能够对图像进行数学处理和分析。

PCA降低维度k-means.

离中心点最近的就是刚刚的基底，就是visual vocabulary

<img src="notes_images/聚类.jpg">



#### K-means 

核心公式：

<img src ="notes_images/WechatIMG38.jpg">

- **Level 0**：整个图像作为一个大的区域进行特征提取。
- **Level 1**：图像被分为四个区域（2x2网格），在每个区域提取特征。
- **Level 2**：图像被进一步细分，例如分成16个区域（4x4网格），并在每个小区域内提取特征。

# Lec7 Recognition

##### k-Nearest Neighbor with pixel distance **never used.

1. **被遮挡（Occluded）**：图像中的某些部分被黑色矩形遮挡，这可能会对图像识别产生很大影响，但如果我们仅仅计算像素值的差异，这种遮挡的影响可能并不明显。
2. **移动（Shifted）**：整个图像向某个方向移动了一个像素，这在视觉上几乎是不可检测的，但从像素值的角度来看，这会造成每个像素都有变动，导致高像素距离。
3. **色调改变（Tinted）**：整个图像被添加了一个色调滤镜，虽然这种改变在视觉上是显著的，但在像素级别的距离可能并没有那么大。

###### 1 hot vector 

#### wx+b

<img src="notes_images/modelsize.jpg" style="zoom:25%;" >

简化：只有4个pixel，flatten 成一个vector

预测值不是onehot 的 =>那就取最大的

<img src="notes_images/3class.jpg" style="zoom:25%;" >



SVM:在低维空间不好分的时候，把数据映射到高纬空间去

**"support vectors"**是指那些位于决策边界附近的数据点。简单来说，这些点正好位于分割两个类别的边界上，或者说，它们离决策界限最近。在SVM中，决策边界是通过最大化两个类别之间的边界（或称为边缘）来确定的，而support vectors就是确定这个边界的关键元素。

<img src="notes_images/nonlinearsvm.jpg" style="zoom:25%;" >

<img src="notes_images/map.jpg">

##### Neural networks: the original linear classifier

(Before) Linear score function:
$$
\begin{gathered}
f=W x \\
x \in \mathbb{R}^D, W \in \mathbb{R}^{C \times D}
\end{gathered}
$$


W是权重矩阵, C是类别数量，D是特征数量

##### Neural networks: 3 layers

(Before) Linear score function: $\quad f=W x$
(Now) 2-layer Neural Network $\quad f=W_2 \max \left(0, W_1 x\right)$​ or 3-layer Neural Network
$$
\begin{gathered}
f=W_3 \max \left(0, W_2 \max \left(0, W_1 x\right)\right) \\
x \in \mathbb{R}^D, W_1 \in \mathbb{R}^{H_1 \times D}, W_2 \in \mathbb{R}^{H_2 \times H_1}, W_3 \in \mathbb{R}^{C \times H_2}
\end{gathered}
$$
(In practice we will usually add a learnable bias at each layer as well)



##### 全连接层(FC layer)

全连接层（Fully Connected Layer，FC Layer）是神经网络中的一个重要概念，尤其在传统的多层感知器（Multilayer Perceptrons, MLPs）中扮演着关键角色。在全连接层中，神经元与前一层中的每一个神经元都有连接，这意味着每个神经元的输入都是前一层所有神经元的输出。

特点

	•	密集连接： 每个神经元都与前一层的所有神经元相连接。
	•	参数数量： 由于密集的连接性，全连接层往往拥有较多的参数。这些参数包括权重（weights）和偏置（biases）。
	•	功能： 全连接层通常用于将前面层的非线性组合的特征进行进一步的组合和抽象，使得网络能够学习到更复杂的特征表示。
	•	用途： 在深度学习模型中，全连接层常常被用在网络的末端，用以进行分类或回归任务。例如，在卷积神经网络（CNN）中，全连接层通常位于卷积层和池化层之后，用于对特征进行汇总和分类。

实现

全连接层的实现可以通过矩阵乘法加上偏置项的方式来完成。如果将前一层的输出表示为一个向量，那么全连接层的计算可以表示为：


其中，激活函数是非线性函数，如ReLU、Sigmoid或Tanh等，用于增加网络的非线性能力，使网络能够学习更复杂的特征。

##### 神经网络（Neural Network)

一个广义术语，而这种具体的网络结构被更准确地称为“fully-connected networks”或者“multi-layer perceptrons”（MLP）。在实践中，我们通常也会在每层添加一个可学习的偏置项（bias），虽然在这个公式中没有明确显示。偏置项可以帮助模型更好地拟合数据。

基础概念： **线性分类器的概念是神经网络中每个单独神经元的工作原理**。在最简单的形式中，一个神经元接受输入，应用一个权重，加上偏置，然后产生输出。如果没有非线性激活函数，这个过程是线性的。

**线性分类器可以看作是没有隐层和非线性激活函数的单层神经网络。**当你在这个线性分类器上添加非线性激活函数和额外的层时，它就变成了一个多层感知器或深度神经网络。

1. 线性得分函数 (Before): 与之前相同，线性得分函数 $f=W x$ 表示一个基础的线性分类器, 没有中间层或非线性激活函数。

2. 2 层神经网络 (Now): 这个模型添加了一个中间或 "隐藏" 层, 以及非线性激活函数 ReLU。计算方式是 $f=W_2 \max \left(0, W_1 x\right)$​ 。

   > 虽然说是 2层，实际上是包含一个输入层，一个隐藏层和一个输出层的网络结构。

   

3. 3 层神经网络: 这里引入了第三层, 使模型更深, 能够捕捉更复杂的特征。计算方式是 $f=W_3 \max \left(0, W_2 \max \left(0, W_1 x\right)\right)$ 。这里, 我们看到嵌套的 ReLU激活函数, 它引入了更多的非线性。



#### 最近邻 (NN) 分类器

#### 优点:

- **简单实现**: 最近邻算法在概念上很简单，且实现容易。
- **决策边界非线性**: NN可以捕获训练数据中的复杂模式，因为它不假设数据是线性可分的。
- **适用于任意数量的类别**: 可以用来做多类别的分类问题。
- **非参数方法**: 不需要假设数据的分布，能够适应任何形状的数据分布。

#### 劣势:

- **需要好的距离函数**: 最近邻算法的效果很大程度上依赖于选择合适的距离度量。
- **测试时慢**: 需要与训练集中的每个点计算距离，这在测试阶段会非常慢，尤其是当训练集很大时。

#### 线性分类器

#### 优点:

- **低维参数表示**: 线性模型通常由权重和偏置项组成，这意味着参数的数量与数据的维度成线性关系，而不是数据量的大小。
- **测试时非常快**: 一旦模型被训练，分类新的数据点可以通过简单的矩阵乘法和加法来实现，这是非常快的。

#### 劣势:

- **主要适用于两类问题**: 标准形式的线性分类器设计为处理两个类别。虽然可以通过技术如一对多（one-vs-all）来适应多类问题，但这并不是内建的。
- **训练线性函数的方法?**: 必须选择合适的优化方法和损失函数来训练模型。
- **如果数据不是线性可分怎么办?**: 线性模型无法捕捉类别之间复杂的决策边界。可以通过引入核技巧或使用更高级的模型来解决这个问题。

其中 $x$ 是输入特征向量, $W_1 、 W_2$ 、和 $W_3$ 是权重矩阵。 $H_1$ 和 $H_2$ 表示不同隐藏层的神经元数量。每个权重矩阵后都跟着一个ReLU激活函数, 这增加了模型的非线性。

##### Multiclass SVM loss

Given an example $\left(x_i, y_i\right)$ where $x_i$ is the image and where $y_i$ is the (integer) label, and using the shorthand for the scores vector: $s=f\left(x_i, W\right)$
the SVM loss has the form:
$$\begin{aligned}
L_i & =\sum_{j \neq y_i} \begin{cases}0 & \text { if } s_{y_i} \geq s_j+1 \\
s_j-s_{y_i}+1 & \text { otherwise }\end{cases} \\
& =\sum_{j \neq y_i} \max \left(0, s_j-s_{y_i}+1\right)
\end{aligned}$$
<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240301232713889.png" alt="image-20240301232713889" style="zoom:50%;" />

```python
def L_i_vectorized(x,y,W):
  scores = W.dot(x)
  margins = np.maximum(0,scores - scores[y]+1)
  margins[y] = 0
  loss_i = np.sum(margins)
  return loss_i
```

$$L(W)=\frac{1}{N} \sum_{i=1}^N L_i\left(f\left(x_i, W\right), y_i\right)+\lambda R(W)$$

**Data loss:** Model predictions should match training data
**Regularization:** Model should be "simple", so it works on test data

**Occam's Razor**:"Among competing hypotheses, the simplest is the best" William of Ockham, $1285-1247$

In common use:
L2 regularization
$$R(W)=\sum_k \sum_l W_{k, l}^2$$

L1 regularization
$$R(W)=\sum_k \sum_l\left|W_{k, l}\right|$$

Elastic net (L1 + L2)
$$R(W)=\sum_k \sum_l \beta W_{k, l}^2+\left|W_{k, l}\right|$$
scores $=$ unnormalized log probabilities of the classes.
$$P\left(Y=k \mid X=x_i\right)=\frac{e^{s_k}}{\sum_j e^{s_j}} \quad \text { where } \quad s=f\left(x_i ; W\right)$$

$$L_i=-\log P\left(Y=y_i \mid X=x_i\right)$$

#### Convolutional Layer

**Convolve**  the filter with image ,i.e "silde over the image spatcially computing dot products"

<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240303002622335.png" alt="image-20240303002622335" style="zoom:50%;" />

1. **第一层**：输入图像的尺寸是32x32，并且有3个颜色通道。通过使用6个5x5x3的滤波器进行卷积，输出的深度变成了6（因为有6个滤波器），每个滤波器都会产生一个特征图。由于滤波器的尺寸是5x5，所以在每个方向上（宽度和高度），图像的尺寸都会减少4个像素（这是由于没有使用任何填充，且步长为1，所以 32−5+1=2832−5+1=28）。因此，经过第一层卷积后，输出的体积是28x28x6。
2. **激活函数ReLU**：卷积之后通常会接一个激活函数，如ReLU（Rectified Linear Unit），它的作用是增加非线性，使得网络能够学习和表示更复杂的函数。
3. **第二层**：在这个例子中，第二层也是一个卷积层，使用的是10个5x5x6的滤波器。注意这里的滤波器深度是6，与前一层的输出深度相匹配。再次应用卷积会导致每个方向上的尺寸减少4个像素（因为没有填充且步长为1），从而输出的体积变为24x24x10。
4. **空间缩减**：文本提示中提到“空间体积快速缩减不好，效果不佳”（Shrinking too fast is not good, doesn't work well）。这句话的意思是，如果每一层都大幅减小特征图的宽度和高度，那么可能会丢失过多的信息，这可能会对网络识别图像中的模式造成不利影响。







假设输入数据的尺寸是 $W_1 \times H_1 \times C$ :
- $W_1$ 代表输入数据的宽度
- $H_1$ 代表输入数据的高度
- $C$ 代表输入数据的深度或通道数

卷积层需要 4 个超参数:
- 滤波器数量 $K$
- 滤波器尺寸 $F$

・步长 $S$
・零填充 $P$
卷积层将会产生一个 $W_2 \times H_2 \times K$ 的输出体积，其中:
- $W_2$ 是输出体积的宽度, 计算公式为 $\left(W_1-F+2 P\right) / S+1$
- $H_2$ 是输出体积的高度, 计算公式与宽度相同

参数数量: $F^2 C K$ 和 $K$ 个偏置
- 这里的 $F^2 C K$ 指的是所有滤波器的权重数量, 因为每个滤波器有 $F \times F \times C$ 个权重, 总共有 $K$ 个滤波器
- 另外, 每个滤波器还有一个偏置, 所以总共有 $K$ 个偏置

<a href="https://sm.ms/image/bjvqGm7i5PThJwZ" target="_blank"><img src="https://s2.loli.net/2024/03/26/bjvqGm7i5PThJwZ.png" ></a>



#### 卷积层

<a href="https://sm.ms/image/r9kFGL1IbQjHg7i" target="_blank"><img src="https://s2.loli.net/2024/03/26/r9kFGL1IbQjHg7i.png" ></a>

<a href="https://sm.ms/image/UHeIlB9dbYk6cqJ" target="_blank"><img src="https://s2.loli.net/2024/03/26/UHeIlB9dbYk6cqJ.png" ></a>



#### 池化层

- 假设输入的体积大小是 $W_1 \times H_1 \times C$ :
- $W_1$ 是输入的宽度
- $H_1$ 是输入的高度
- $C$ 是通道数, 对于RGB图像, $C$ 会是 3
- 卷积层需要两个超参数:
- 空间大小 $F$ : 这是池化操作覆盖的区域大小
- 步长 $S$ : 这是池化操作在输入数据上移动的像素数
- 这将会产生一个 $W_2 \times H_2 \times C$ 大小的输出, 其中:$W_2$ 是输出的宽度, 计算方式为 $\left(W_1-F\right) / S+1$$H_2$ 是输出的高度, 计算方式与宽度相同: $\left(H_1-F\right) / S+1$
- 参数数量为 0 ：因为池化层不引入任何权重或偏置参数, 它仅仅对输入进行下采样（降低分辨率), 比如取最大值（最大池化）或平均值（平均池化）。

这意味着池化层的目的是减少输入数据的空间大小, 从而减少后续层的参数数量, 以防止过拟合, 并减少计算量。同时, 它也提供了一种形式的平移不变性。



#### 总结

- **ConvNets stack CONV, POOL, FC layers**：卷积神经网络通常由卷积层（CONV）、池化层（POOL）和全连接层（FC）堆叠组成。
- **Trend towards smaller filters and deeper architectures**：趋势是使用更小的滤波器并构建更深的网络架构。
- **Trend towards getting rid of POOL/FC layers (just CONV)**：趋势是去除池化层和全连接层，只使用卷积层。
- **Historically architectures looked like [[CONV-RELU]*N-POOL?]*M-(FC-RELU)\*K,SOFTMAX**：
  - **[CONV-RELU]\*N**：表示N个卷积层和ReLU激活函数的重复单元，N通常最多为5。
  - **-POOL?**：表示可选的池化层。
  - **M**：表示这种模式重复的次数，M的数量较大。
  - **(FC-RELU)\*K**：表示全连接层和ReLU激活函数的组合重复K次，其中K的取值范围是0到2。
  - **SOFTMAX**：是用于分类的激活函数。
- **But recent advances such as ResNet/GoogLeNet have challenged this paradigm**：但是最近的进展，如ResNet和GoogLeNet，已经挑战了这一范式



1. **卷积层（CONV）**：用于提取输入数据中的特征。
2. **激活函数（如ReLU）**：应用非线性变换，增加决策函数的复杂性和网络的深度。
3. **池化层（POOL）**：降低特征维度，减少计算量和防止过拟合。
4. **全连接层（FC）**：计算最终的分类或回归输出。
5. **Softmax层**：在多类分类问题中，用于输出每个类别的预测概率。

传统上，这些层被组织成深度网络，通常在几个卷积层后面跟着一个池化层，再后面是几个全连接层，最后是一个softmax层来进行分类。这种架构通常表示为 [[CONV-RELU]*N-POOL?]*M-(FC-RELU)*K, SOFTMAX，这是一种层次堆叠的设计。





<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240303012109393.png" alt="image-20240303012109393" style="zoom:50%;" />

**全连接层的特点**：全连接层中的每个神经元都与前一层的所有激活连接。这意味着，如果前一层是一个卷积层或池化层，其所有的输出激活值都将作为全连接层每个神经元的输入。

"池化"（Pooling）是卷积神经网络（CNN）中的一个术语，它指的是一种减小数据维度的操作，同时保留重要信息。这种操作通常应用于卷积层提取的特征图上。池化可以帮助减少计算量，内存使用和参数的数量，这有助于防止过拟合，即模型过于复杂导致的在训练数据上表现良好但在未见过的数据上表现不佳的问题。

池化有几种不同的形式，其中最常见的两种是：

1. **最大池化（Max Pooling）**：在这种类型的池化中，从输入特征图的一个小区域（通常是2x2或3x3的区域）中选择最大的元素作为该区域的代表，并在池化输出中保留这个最大值。这种方法非常有效，因为在许多情况下，特征的存在比它们的精确位置更重要。
2. **平均池化（Average Pooling）**：与最大池化类似，平均池化会计算输入特征图的一个小区域内所有元素的平均值，并将这个平均值用作池化输出。这种方法可以保留区域的背景信息，但不如最大池化突出特征。

##### 批量归一化（Batch Normalization）

$$\hat{x}^{(k)}=\frac{x^{(k)}-E\left[x^{(k)}\right]}{\sqrt{\operatorname{Var}\left[x^{(k)}\right]}}$$

这个公式描述了如何对神经网络中某一层的激活值 $x^{(k)}$ 进行归一化处理。这里：

- $\hat{x}^{(k)}$ 是归一化后的激活值。
- $x^{(k)}$ 是原始的激活值。
- $E\left[x^{(k)}\right]$ 是 $x^{(k)}$ 的均值（期望）。
- $\operatorname{Var}\left[x^{(k)}\right]$ 是 $x^{(k)}$ 的方差。

1. 输入: $\mathbf{B}=\left\{x_1 \ldots x_m\right\}$ 是一个mini-batch, 它包含了 $\mathrm{m}$ 个数据样本。
2. 学习的参数: $\gamma, \beta$ 分别是批量归一化层学习的尺度 (scale) 和偏移 (shift) 参数。
3. 输出: $\left\{y_i=B N_{\gamma, \beta}\left(x_i\right)\right\}$ 是经过批量归一化处理后的数据。
   具体的步骤包括：

- 计算mini-batch的均值 $\mu_B$ :
  $$\mu_B \leftarrow \frac{1}{m} \sum_{i=1}^m x_i$$
- 计算mini-batch的方差 $\sigma_B^2$ :
  $$\sigma_B^2 \leftarrow \frac{1}{m} \sum_{i=1}^m\left(x_i-\mu_B\right)^2$$
- 归一化 $\hat{x}_i$ :
  $$\hat{x}_i \leftarrow \frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}$$
- 尺度和偏移 $y_i$ :
  $$y_i \leftarrow \gamma \hat{x}_i+\beta=B N_{\gamma, \beta}\left(x_i\right)$$

其中, $\epsilon$ 是一个很小的数, 防止分母为 0 。

<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240303225058882.png" alt="image-20240303225058882" style="zoom:50%;" />

- Sigmoid函数历史上非常流行，因为它可以很好地模拟生物神经元的饱和“发射率”。换句话说，它可以模拟一个神经元在不同刺激下的响应方式：在低刺激下几乎没有反应，在中等刺激下反应逐渐增强，在高刺激下反应饱和。

- 尽管Sigmoid函数在历史上很流行，但它有一些缺点，如梯度消失问题（在输入值非常高或非常低时，梯度接近于0，这会导致在训练过程中权重几乎不更新）。
- 此外，Sigmoid函数输出不是以0为中心的，这可能导致网络的优化效率降低

传统Machine-learning 会专家手动设计Feature extraction<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240305102850932.png" alt="image-20240305102850932" style="zoom:50%;" />

classification 降维，耗时，人力，每种application 

<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240305103152658.png" alt="image-20240305103152658" style="zoom:50%;" />

很多时候Deep learning 不再需要Validation集了

<img src="/Users/abigale.dong/Library/Application Support/typora-user-images/image-20240305103939845.png" alt="image-20240305103939845" style="zoom:50%;" />



```python
# vanlina gradient descent 
while True:
  weights_grad = evaluate_gradient_loss(loss_fun,data,weights)
  weights += -step_size * weights_grad
```



**反向传播用于计算梯度**，**梯度下降用于使用这些梯度进行权重更新**。

反向传播例子

<a href="https://sm.ms/image/o7GAsy3xp2XRH9n" target="_blank"><img src="https://s2.loli.net/2024/03/26/o7GAsy3xp2XRH9n.png" ></a>

# Lec 9

LeNet-5 迟到错过了没听到

##### Case Study AlexNet



<a href="https://sm.ms/image/Bi4Ex9XrjIQqboh" target="_blank"><img src="https://s2.loli.net/2024/03/26/Bi4Ex9XrjIQqboh.png" ></a>

1. **输入层**：接收一个尺寸为 227x227x3 的图像。这表示图像的宽度和高度各为227像素，具有3个颜色通道（通常为RGB）。
2. **第一卷积层（CONV1）**：使用96个尺寸为 11x11 的滤波器，并且步长（stride）为4，不使用填充（padding）。这个卷积层不改变深度（仍然是96），但会减少空间尺寸。
3. **第一池化层（MAX POOL1）**：使用3x3的滤波器，步长为2进行最大池化。
4. **归一化层（NORM1）**：对卷积层的输出进行归一化处理，以加速训练过程并减少过拟合。
5. **第二卷积层（CONV2）**：使用256个5x5的滤波器，步长为1，并使用2的填充。
6. **第二池化层（MAX POOL2）**：再次使用3x3的滤波器，步长为2进行最大池化。
7. **第二归一化层（NORM2）**。
8. **第三卷积层（CONV3）**：使用384个3x3的滤波器，步长为1，并使用1的填充。
9. **第四卷积层（CONV4）**：与第三卷积层相似，使用相同尺寸和数量的滤波器。
10. **第五卷积层（CONV5）**：同样使用256个3x3的滤波器，步长为1，并使用1的填充。
11. **第三池化层（MAX POOL3）**：使用3x3的滤波器，步长为2进行最大池化。
12. **全连接层（FC6-FC8）**：首先是两个具有4096个神经元的全连接层，然后是一个1000个神经元的全连接层，用于输出1000个类别的分类得分。


$$
\begin{aligned}
& W_{\text {out }}=\frac{W_{\text {in }}-F+2 P}{S}+1 \\
& H_{\text {out }}=\frac{H_{\text {in }}-F+2 P}{S}+1 \\
& D_{\text {out }}=K
\end{aligned}
$$

其中：
- $W_{o u t}$ 和 $H_{\text {out }}$ 是输出体积的宽度和高度。
- $W_{i n}$ 和 $H_{i n}$ 是输入体积的宽度和高度。
- $F$ 是卷积核的尺寸。
- $P$ 是填充的数量（这个例子中没有提到填充，所以我们假设 $\mathrm{P}=0$ ）。
- $S$ 是步长。
- $K$ 是输出深度, 也就是卷积核的数量。
- $D_{\text {out }}$​​ 是输出体积的深度。

<a href="https://sm.ms/image/zqQBLgARnvimWwu" target="_blank"><img src="https://s2.loli.net/2024/03/26/zqQBLgARnvimWwu.png" ></a>

#### 输出体积

由于 AlexNet 的首层卷积不使用填充，我们可以将 $P$ 设为 0 。将这些值代入上述公式中:
$$
\begin{aligned}
& W_{\text {out }}=\frac{227-11+2 \cdot 0}{4}+1=\frac{216}{4}+1=54+1=55 \\
& H_{\text {out }}=\frac{227-11+2 \cdot 0}{4}+1=\frac{216}{4}+1=54+1=55 \\
& D_{\text {out }}=96
\end{aligned}
$$

所以输出体积的大小是 $55 \times 55 \times 96$​​ 。

- **ReLU激活函数**: AlexNet是第一个在CNN中广泛使用ReLU激活函数的网络。相比传统的sigmoid激活函数，ReLU能够加速训练过程并减少梯度消失问题，它非常有效地增加了神经网络对图像特征的学习能力。
- **LRN层（局部响应归一化）**: 在AlexNet中，LRN层被用来模仿生物神经系统中的侧抑制，通过局部归一化增强模型的泛化能力。然而，随着更高效的归一化技术（如批量归一化）的出现，LRN层已经不再常用。
- **大量的数据增强**: 数据增强通过对训练图像进行各种转换（如翻转、旋转、缩放等）来增加数据多样性，这有助于防止过拟合并改善模型在新数据上的表现。AlexNet通过这种方式显著地增加了训练数据的有效量。
- **Dropout 0.5**: Dropout是一种正则化技术，它在训练过程中随机丢弃（即设置为零）网络中的某些神经元的输出，以避免网络过于依赖于某些局部特征，从而增加网络的泛化能力。在AlexNet中，dropout比率被设置为0.5，即有一半的概率神经元的输出在训练过程中会被置零。
- **批量大小128**: 训练时使用的每批数据的大小为128。这个批量大小是在计算资源和内存使用之间权衡的结果。
- **SGD动量0.9**: AlexNet使用了带有动量的随机梯度下降（SGD）来训练网络。动量帮助加速梯度下降在相关方向上的收敛，并减少振荡，动量系数被设置为0.9。
- **学习率1e-2，当验证精度停滞时手动减少10倍**: AlexNet的初始学习率设置为0.01，当验证集上的精度不再提高时，学习率会手动减少到原来的十分之一。这是一种常见的技巧，用于微调网络以提高性能。
- **L2权重衰减5e-4**: 权重衰减是正则化的一种形式，通过对网络权重施加惩罚来避免权重变得太大，从而减少过拟合。在AlexNet中，L2权重衰减系数设置为0.0005。
- **7个CNN集成**: AlexNet采用了模型集成的策略，将7个独立训练的CNN模型的输出进行平均，得到最终结果。这种方法将错误率从18.2%降低到了15.4%，证明了集成方法在提高模型准确度方面的有效性。



- **Trained on GTX 580 GPU with only 3 GB of memory**: 指的是AlexNet是在NVIDIA GTX 580显卡上训练的，这张显卡只有3GB的显存。对于当时的深度学习模型而言，这是相对较小的显存容量，意味着网络模型和数据批次大小的选择必须适应这个硬件限制。
- **Network spread across 2 GPUs, half the neurons (feature maps) on each GPU**: 由于单个GPU显存大小有限，AlexNet的网络被设计为可以跨两个GPU运行。其设计将一半的神经元（特征图）放在一个GPU上，另一半放在另一个GPU上。这不仅是因为显存限制，还因为这样做可以加速计算过程。在AlexNet的实际实现中，有些层的神经元仅与同一GPU上的神经元相连接，而有些层则与两个GPU上的神经元相连接，以保持通信并同步学习



#### VGG

VGG网络的一个关键特性是使用多个连续的3x3的卷积层（每个都跟随一个激活函数），然后是一个2x2的最大池化层。这种结构可以有效地捕获图像特征，并且由于相对较小的卷积核，它可以用更深的架构来实现而不是只用一个大的卷积核。此外，这种方式可以减少参数的数量，提高了计算效率。

<a href="https://sm.ms/image/wuX6bBeWyYTMFOP" target="_blank"><img src="https://s2.loli.net/2024/03/26/wuX6bBeWyYTMFOP.png" ></a>

filter 越来越大，希望不用增加太多网络参数

###### "Q: What is the effective receptive field of three 3x3 conv (stride 1) layers?" 

这是一个关于卷积神经网络中感受野概念的问题。**感受野**是指输入图像上能影响CNN中某一层输出的区域大小。在这个例子中，我们有三个连续的3x3大小的卷积层，每个卷积层的步长为1。这意味着每个卷积核覆盖输入特征图的3x3区域，每次移动一个像素。

我们可以通过计算来确定三层3x3卷积层（步长为1）后的有效感受野大小。简单地说，对于步长为1的3x3卷积层，每经过一层，感受野的大小会在每个方向上增加2个单位（因为3x3的核会在原来的基础上多覆盖前后左右各一个像素）。所以，第一层后感受野是3x3，第二层后是5x5（3加上左右各一格），第三层后是7x7。

图片右侧部分展示了VGG16和VGG19网络的结构。这两个网络的差异在于层的数量和深度，VGG16有16个权重层，而VGG19有19个。这些层包括了卷积层，最大池化层，以及最后的全连接层。卷积层主要用于提取图像的特征，池化层用于降维，全连接层则用于将特征映射到最终的分类结果。

图片中的网络结构图还展示了网络中每个卷积层后的通道数（例如，第一层后是64通道，最后一层可能是512通道），这表示在该层中每个卷积核的数量。每一层卷积层后面通常会跟一个激活函数，最常用的是ReLU激活函数。

1. **3x3 卷积 (步幅 1) (n层, m通道)**
   - 这表明在VGG网络中使用了大小为3x3的卷积核，步幅为1。步幅（stride）是卷积核在输入数据上滑动的步长。步幅为1意味着卷积核每次移动一个像素点。
   - “n层”表示这样的卷积层堆叠了n次。VGG网络特别之处在于它通过堆叠多个3x3卷积层来增加网络的深度。
   - “m通道”意味着每个卷积层有m个不同的卷积核（也就是这层输出m个通道的特征图）。
2. **2x2 最大池化层 (步幅 2)**
   - 最大池化层（MaxPooling）用于降低特征图的空间维度（高度和宽度），同时保持重要特征。2x2的池化窗口会考虑每个2x2的区域，并取该区域的最大值作为输出。
   - 步幅2表示池化窗口每次移动2个像素，这导致输出特征图的大小是输入的一半。

以上的结构是VGG网络中的一个小部分，但这些是构建这个网络的基本构件。VGG网络通过重复这样的结构来构建一个非常深的网络，从而能够学习图像的复杂特征。VGG16和VGG19是这种结构的两个变种，它们的区别在于层的数量（分别有16层和19层卷积层和全连接层）。

在上一个图片中提到的有效感受野是指卷积神经网络中某一层的神经元相对于输入图像的视野大小。通过叠加多个卷积层，每一层的神经元都能“看到”输入中更大的区域，这就是有效感受野增加的原理。对于连续的3个3x3卷积层（每层的步幅为1），每增加一个这样的卷积层，有效感受野都会增加2个像素（因为3x3的核覆盖了3个像素，减去1是因为中间有重叠）。所以，通过叠加三个这样的层，第三层的有效感受野会是7x7，因为 3+2∗(3−1)=73+2∗(3−1)=7。

对于第一层卷积（CONV1）：
- 每个滤波器的尺寸是 $11 \times 11$ 。
- 我们有 3 个输入通道（RGB图像）。
-一共有 96 个这样的滤波器。

每个滤波器有 $11 \times 11 \times 3$ 个权重（每个输入通道一个权重），加上一个偏置项。所以，单个滤波器有 $11 \times 11 \times 3+1$ 个参数。

现在, 既然我们有 96 个这样的滤波器, 那么总参数数量将是 $96 \times(11 \times 11 \times 3+1)$ 。

###### Parameters (params): 

这些是该层学习的权重和偏置的数量。例如, 第一个卷积层有 64 个 $3 \times 3$大小的滤波器, 这意味着有 $3 * 3 * 3 * 64$ 个权重（因为每个滤波器在 3 个通道上都有一个 $3 \times 3$的权重矩阵), 还有64个偏置, 所以总共是 1,728 个参数。

###### Memory: 

对于卷积层, 所需的内存量与层的输出尺寸（例如 $224 * 224 * 64$ ) 和每个激活值占用的内存量（通常是一个浮点数）相关。例如, 如果每个激活值是32位浮点数, 那么一个激活值就需要4字节的内存。

1. **左侧的Naive Inception module**：
   - 输入是 `28x28x256`，即有256个通道的28x28像素的特征图。
   - 进行四个并行操作：
     - `1x1 convolution with 128 filters`：使用128个1x1的滤波器进行卷积，它的作用通常是进行特征降维，减少后续层的计算负担。
     - `3x3 convolution with 192 filters`：使用192个3x3的滤波器进行卷积，可以捕获相对较大区域的特征。
     - `5x5 convolution with 96 filters`：使用96个5x5的滤波器进行卷积，捕获更大区域的特征。
     - `3x3 max pooling`：对输入进行最大池化操作，之后的输出通常会接一个`1x1 convolution`（不是在这个图里显示），用于降维。
   - 所有操作的输出最后在通道维度上进行合并，合并后的输出尺寸是 `28x28x(128+192+96+256)=28x28x672`，通道数是各部分输出通道数之和。
   
2. **右侧的Naive Inception module**：
   - 结构和左边的类似，但滤波器的数量和一些维度有所不同。
   
   - 这个模块的具体操作和左边的相同，但每个卷积操作和池化操作后的`1x1 convolution`的滤波器数量有所变化。
   
   - 合并后的输出尺寸会是 `28x28x(128+192+96+64)=28x28x480`。
   
     
   
     <a href="https://sm.ms/image/RBxW2tK5O6g8FT1" target="_blank"><img src="https://s2.loli.net/2024/03/26/RBxW2tK5O6g8FT1.png" ></a>



- **22层**: GoogLeNet有22层深的结构。
- **高效的“Inception”模块**: 这个模块使得网络在不增加太多参数的情况下能够捕获复杂的特征。
- **避免昂贵的全连接（FC）层**: 全连接层参数多，计算量大，GoogLeNet通过替代设计提高了效率。
- **参数数量是AlexNet的12分之一，是VGG-16的27分之一**: 这使得网络更加轻量级，需要的计算资源更少。
- **ILSVRC'14分类赛事冠军（6.7%的top 5错误率）**: GoogLeNet在2014年的ImageNet挑战赛中取得了优异的成绩。

# Lec10

<a href="https://sm.ms/image/R12JgPeGtbAvX7E" target="_blank"><img src="https://s2.loli.net/2024/04/02/R12JgPeGtbAvX7E.png" ></a>



classification 和regression 是有什么区别

1. **分类（Classification）**:
   - 分类是预测离散响应的过程。
   - 输出变量被限制在两个或多个类别之间，比如垃圾邮件检测（垃圾邮件或非垃圾邮件），图像识别（猫、狗、鸟等）。
   - 结果是类别标签（如“是”或“否”）。
   - 常用的分类算法包括决策树、支持向量机和神经网络。
2. **回归（Regression）**:
   - 回归是预测连续响应的过程。
   - 输出变量可以取任何实数值，例如房屋价格、温度或销售额等。
   - 结果是实数值（如“150.5”）。
   - 常见的回归算法包括线性回归、岭回归和LASSO回归。

简单来说，如果你的目标是预测类别，那么你会使用分类方法；如果你的目标是预测一个数量，那么你会使用回归方法。

1. **检测特定实例（模板）问题**：在这个上下文中，检测一个给定的实例（或模板，即特定的图像或物体）时，相似度得分可能足够用。这意味着如果我们有一个具体的目标（比如特定的人脸或特定的物体），我们可以通过比较不同区域与模板之间的相似度来定位它。但是，如果要检测给定类别的任何对象（如任何汽车，而不是特定的汽车），我们需要强大的特征和好的分类器。这里所说的“强特征”是指能够捕捉类别内不同实例共有特征的那些属性，而“好的分类器”是指能够区分不同类别并正确标记它们的算法。
2. **未知位置、尺度和长宽比的问题**：当物体的位置、尺度（大小）和长宽比（形状）未知时，搜索空间变成了四维的（包括物体在图像中的x位置、y位置、尺度和长宽比）。为了有效地进行搜索，需要比穷尽搜索更好的方法。穷尽搜索意味着测试所有可能的位置和大小，这在计算上是非常昂贵的。我们需要更智能的搜索方法来减少所需的计算量，如使用机器学习算法，这些算法可以学习物体的特征，并快速地在图像中找到匹配项。



<a href="https://sm.ms/image/LjbrDspeH52tzFu" target="_blank"><img src="https://s2.loli.net/2024/04/02/LjbrDspeH52tzFu.png" ></a>

**可变形部件模型（Deformable Part Model，简称DPM）**的计算机视觉模型。该模型是由Felzenszwalb等人在2008年提出的，用于物体识别任务，特别是在计算机视觉领域中。

- **外观由HOG表示**：HOG（Histogram of Oriented Gradients）是一种特征描述符，它通过统计图像一小部分区域内梯度方向的分布来描述该区域的外观和形状。这些梯度（或边缘）方向在局部图像区域内被统计，生成了特征向量。这些特征向量被用来在图像中检测和描述局部物体的外观。
- **空间配置启发于“图像结构”**：图像结构（pictorial structures）是一种用于解释物体部件之间空间关系的框架。它把物体模型化为由多个部件组成，这些部件在空间上的相对位置遵循某种统计模型。这种方法可以用来处理变形，因为模型可以适应部件之间的相对位置变化。
- **部位位置被视为潜在变量**：潜在支持向量机（Latent SVM）是一种学习模型，它结合了支持向量机（SVM）的强大分类能力和潜在变量模型的能力来处理不完全标记的训练数据。在DPM中，物体的部件位置被视为潜在变量，意味着它们不是直接观察到的，而是需要在学习过程中推断出来

<a href="https://sm.ms/image/JihOKUc7WN896aZ" target="_blank"><img src="https://s2.loli.net/2024/04/02/JihOKUc7WN896aZ.png" ></a>

- **选择性搜索（SS）**：这是一种用于物体识别任务的计算机视觉技术，旨在代替传统的滑动窗口技术，以更高效地生成物体候选区域（object proposals）。传统的滑动窗口方法会在所有尺寸和位置上评估窗口，计算量巨大。选择性搜索通过合并相似的区域来减少候选区域的数量，从而减少了搜索空间并提高了效率。
- **输入图像**：这是算法处理前的原始图像，用于生成物体的候选区域。
- **地面真相（Ground Truth）**：这是图像的手工标记或理想的分割结果，显示了图像中真实物体的确切位置。在这个例子中，地面真相是一头牛的完整轮廓。
- **层次分组（Hierarchical Grouping）**：这个过程是选择性搜索算法的核心，它从图像中的小区域开始，基于颜色、纹理、尺寸和形状兼容性等相似性度量逐步合并这些区域。这种分组过程以层次的方式进行，最终形成较大的区域。
- **对象提案（Object Proposals）**：这是选择性搜索算法的输出，它提供了图像中可能存在物体的区域。这些区域是算法认为有最高概率包含物体的地方。在这个例子中，算法生成了几个不同大小和位置的框，这些框大致覆盖了牛的位置。

<a href="https://sm.ms/image/LjbrDspeH52tzFu" target="_blank"><img src="https://s2.loli.net/2024/04/02/LjbrDspeH52tzFu.png" ></a>

<a href="https://smms.app/image/yl6deowfKQVUhbx" target="_blank"><img src="https://s2.loli.net/2024/04/02/yl6deowfKQVUhbx.png" alt="image.png"></a>
